---
title: "Procedural Learning 110320"
author: "Ola Ozernov-Palchik & Zhenghan Qi"
date: "03/03/2021"
output:
  word_document: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r Clean and organize, include=FALSE,warning = FALSE}
# Clearn and organize data
#import packages
Packages <- c("dplyr", "stats", "psych", "ggplot2", "lme4",
              "gridExtra", "dplyr","caret","tidyverse",
              "plyr","lmerTest","ggpubr","nlme","emmeans","rstatix","ggbeeswarm",
              "arsenal","sjstats","r2glmm"
)

lapply(Packages, library, character.only = TRUE)
source("corstars_function.R")

####Organizational ####

#set subject directory
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))


#import pocedural.csv file
d <- read.csv('procedural_data072320.csv',stringsAsFactors = FALSE,skipNul = TRUE,
              blank.lines.skip = TRUE)

groups<-read.csv("abcd_group.csv")
names(groups)[names(groups)=="ID"] <- "PartID"
names(d)[names(d)=="abcd_id"] <- "PartID"
d<-merge(d,groups,'PartID')
SL=read.csv("sl_analysis/all_sl_wide.csv")

#Rename variables and organize

#exclude ineligible participants
d<-d%>%filter(d$PartID!='ABCD_1718')
d<-d%>%filter(d$PartID!='ABCD_1728')

d<-d%>%filter(d$Subgroup=="TYP"| d$Subgroup=="DD")

```

# Sample Size
```{r, echo=FALSE,warning = FALSE}
local({
  .Table <- xtabs(~Subgroup, data=d)
  cat("\nFrequency table:\n")
  print(.Table)
})
```
# Descriptives Table
```{r, echo=FALSE,warning = FALSE}
names(d)[names(d)=="background_age"] <- "Age"
names(d)[names(d)=="background_sex"] <- "Sex"
names(d)[names(d)=="wrmt_wa_ss_2"] <- "WA"
names(d)[names(d)=="ran_letters_ss_2"] <- "RAN_Letters"
names(d)[names(d)=="wrmt_id_ss_2"] <- "WID"
names(d)[names(d)=="towre_sw_ss_2"] <- "SWE"
names(d)[names(d)=="towre_pde_ss_2"] <- "PDE"
names(d)[names(d)=="ppvt_vocab_ss_2"] <- "Vocabulary"
names(d)[names(d)=="gort_ori_ss_2"] <- "ORI"
names(d)[names(d)=="ctopp_blending_ss_2"] <- "Blending"
names(d)[names(d)=="ctopp_elision_ss_2"] <- "Elision"
names(d)[names(d)=="ctopp_nonword_ss_2"] <- "Nonword"
names(d)[names(d)=="ran_2set_ss_2"] <- "RAN_2Set"
names(d)[names(d)=="ran_objects_ss_2"] <- "RAN_Objects"
names(d)[names(d)=="wais_dsb_ss_2"] <- "DigitsBackward"
names(d)[names(d)=="wais_dsf_ss_2"] <- "DigitsForward"
names(d)[names(d)=="kbit_ss_2"] <- "IQ"
d$DigitsForward=ifelse(d$DigitsForward==88,8,d$DigitsForward)#correct one typo
names(d)[names(d)=="wais_total_ss_2"] <- "DigitsSpan"
adult_table<-d%>%ungroup%>%dplyr::select(Subgroup,Sex,Age,IQ,WID,WA,SWE,PDE,
                                       Vocabulary,ORI,Elision,ORI,Nonword,RAN_2Set,DigitsForward,DigitsBackward)
abcd_b<-na.omit(adult_table)
table(abcd_b$Subgroup,abcd_b$Sex) #1=Female, 2=Male
summary(tableby(Subgroup ~ ., data = adult_table,
                     control=tableby.control(numeric.stats="meansd", total=FALSE)),title = " Descriptives",text=TRUE,digits=2, digits.p=3)
#arsenal::write2word(at, "descriptives.doc", title="Descriptives")

#cohens_d(d$DigitsForward~ d$DD, var.equal = TRUE)

```

# Demographics
```{r, echo=FALSE,warning = FALSE}
demo<-read.csv("abcd_demo.csv")
d_demo<-merge(demo, d)
x<-d%>%ungroup%>%dplyr::select(Subgroup,Age,IQ,WID,WA,SWE,PDE,
                                       Vocabulary,ORI,Elision,ORI,Nonword,RAN_2Set,DigitsForward,DigitsBackward)
x<-na.omit(x)

d_demo<-merge(d_demo,x)
table(d_demo$read_delay,d_demo$Subgroup)
table(d_demo$lang_delay,d_demo$Subgroup)
table(d_demo$ADHD,d_demo$Subgroup)
demo_table<-d_demo%>%dplyr::select(Subgroup,read_delay,lang_delay,dyslexia,ADHD,self_ed,starts_with('race'),household_income,Sex)

demo_table$self_ed <- factor(demo_table$self_ed,
                                levels = c(1,2,3,4,5,6,7),
                                labels = c("Less7Grd", "JuniorHigh", "HighSchool","PartialCollege","College","Masters","Doctorate"))
demo_table$household_income <- factor(demo_table$household_income,
                                levels = c(1,2,3,4),
                                labels = c("<30k", "30-60k", "60-100k",">100k"))

cat.names = demo_table %>% select_if(is.integer) %>% colnames()
demo_table2=demo_table
demo_table2[,cat.names] = lapply(demo_table2[,cat.names], as.factor)
str(demo_table2[,cat.names])

at<-summary(tableby(Subgroup ~ ., data = demo_table2,
                     control=tableby.control(numeric.stats="meansd", total=FALSE)),title = "Adult Descriptives",text=TRUE,digits=2, digits.p=3)
at
#cohen.d(abcd_b$DigitsForward~abcd_b$Subgroup)

```


# Rotary Pursuit

```{r, include=FALSE}
## Extract and organize tasks
PL<-d[c(1,188,3:4,54:70,71:80)]

rp <- NULL
rp <- data.frame('PartID'= character(),'Subgroup' = character(),'plType' = character(),'trial' = double(),
                      'On' = double(),'Off' = double(),stringsAsFactors=FALSE)

for (i in 1:nrow(PL)) {
  if (PL[i,10] == ""){ #if null go to next line
    next()
  }
  for(k in 6:21){
    on <- as.numeric(trimws(strsplit(PL[i,k],';')[[1]][1]))
    off <- as.numeric(trimws(strsplit(PL[i,k],';')[[1]][2]))
    Subgroup <- PL[i,2]
    if (nrow(rp) == 0) {
      rp[1,] <- c(PL[i,1],as.character(PL[i,2]),'rp',k-5,on,off)    }
    else {
      rp[nrow(rp) + 1,] <- c(PL[i,1],as.character(PL[i,2]),'rp',k-5,on,off)
    }
  }
}

rp$On <- as.numeric(rp$On)
rp$Off <- as.numeric(rp$Off)
rp$trial <- as.numeric(rp$trial)

rp2<-rp%>%group_by(PartID,Subgroup,trial)%>%
                         dplyr::mutate(prop_on=On/(On+Off))

plot(rp2$prop_on~rp2$trial)
 # left_join(d)

# Check # of trials per each subject
data_tmp4check <- aggregate(prop_on ~ PartID * Subgroup, FUN=NROW, data = rp2 )
unique(data_tmp4check[data_tmp4check$trial != 16,])
#View(data_tmp4check)
length(unique(d$PartID))
data_tmp4check[data_tmp4check$trial !=16,1]
hist(rp2$prop_on)
```

### RP Statstical Analysis by Trial

#### RP Baseline differences
- There is no significant group difference in baseline speed for RP.
```{r,echo=FALSE,warning = FALSE}
t.test(d$rotarypursuit_0_2~d$Subgroup)
m1<-lm(rotarypursuit_0_2~Age+Sex+Subgroup,data=d)
anova(m1)
#sjstats::eta_sq(m1)
r2beta(m1, method = "nsj")


```

#### RP Realiability ####
```{r,echo=FALSE,warning = FALSE}
rp3<-rp2%>%ungroup%>%dplyr::select(PartID,prop_on,trial)
rp_w<- spread(rp3, trial, prop_on)
table(rp_w$Subgroup) #sample for RP
rp_w<-dplyr::select(rp_w,-PartID)
psych::alpha(rp_w)

```


```{r, echo=FALSE,warning = FALSE}
rp2$PartID = as.factor(rp2$PartID)
rp2$Subgroup = as.factor(rp2$Subgroup)
rp2_age_gender_iq = merge(rp2,d[,c(1,3,4,6)],all.x=TRUE)
```

#### RP Linear mixed-effect modeling
- model with trial and participant as random effects (controlling for age and sex)
- borderline significant effect trial x subgroup (faster learning in Dys)

```{r, echo=FALSE,warning = FALSE}
lmerrp1 <- lmer(prop_on~Subgroup*trial +Age+Sex + (1|PartID),data=rp2_age_gender_iq)
lmerrp2 <- lmer(prop_on~Subgroup*trial +Age+Sex + kbit_ss+ (1+trial|PartID),data=rp2_age_gender_iq)
#lmerrp3 <- lmer(prop_on~Subgroup*trial +Age+Sex + (1|trial),data=rp2_age_gender_iq)
anova(lmerrp1,lmerrp2)
anova(lmerrp2) #borderline significant effect for Subgroup x trial
#sjstats::eta_sq(lmerrp2)
r2beta(lmerrp2, method = "nsj")
summary(lmerrp2)
```
- within DD group
```{r, echo=FALSE,warning = FALSE}
lmerrp2_DD <- lmer(prop_on~trial+Age+Sex +kbit_ss+(1+trial|PartID),data=rp2_age_gender_iq[rp2_age_gender_iq$Subgroup=="DD",])
summary(lmerrp2_DD)
```
- within TYP group
```{r, echo=FALSE,warning = FALSE}
lmerrp2_TYP <- lmer(prop_on~trial+Age+Sex +kbit_ss+(1+trial|PartID),data=rp2_age_gender_iq[rp2_age_gender_iq$Subgroup=="TYP",])
summary(lmerrp2_TYP)
```
#### RP Plot by trial 

```{r, echo=FALSE,warning = FALSE}

rp2$trial<-as.integer(rp2$trial)

rpPlot<-dplyr::summarise(group_by(rp2,Subgroup,trial), n = n(),
                         mean=mean(prop_on,na.rm = T), sd=sd(On/(On+Off),na.rm = T),se = sd/sqrt(n))

rp_plot<-ggplot(data = rpPlot, aes(x=trial, y=mean, color=Subgroup))+
  geom_line(size=1.5) +geom_point(size=2)  +
 scale_color_manual(values=c('#00BDD0','#E7861B'))+
  geom_errorbar(aes(ymin=mean-se,ymax=mean+se),
                 width=.2,  size=0.5)+
  scale_x_continuous(breaks=seq(1,16,1))+
  #scale_y_continuous(limits = c(0.2, 0.5))+
  theme(
    axis.title = element_text(family = "Times New Roman", size = 20),
    legend.key.size = unit(1, "cm"),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15))  +
  labs(x = "Trials", y = "Proportion On (secs)") +
  theme(panel.background = element_rect(fill = "white", colour = "grey50"),panel.border=element_blank(),text=element_text(size=16,family="Times New Roman"),legend.key.size = unit(0.8, "cm"),
    legend.text = element_text(
      size = 16,
      face = 'bold'
    ),
     legend.title = element_blank(),)+
  theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))


rp_plot2<-rp_plot + theme(legend.position = "none")
ggsave("rp011222.png",width=6, height=4)

#save legend seperatly
g_legend <- function(a.gplot){
  tmp <- ggplot_gtable(ggplot_build(a.gplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}

mylegend <- g_legend(rp_plot)
library(grid)
grid.draw(mylegend)

```

### RP Slope Analysis

```{r, echo=FALSE, include=FALSE,warning = FALSE}
d_glm_fit_list <- vector(mode = "list", length = nrow(rp)*2)
index <- 0
abcd_ids=unique(rp2$PartID)
b_list=c()
m_list = c()

for (subj in abcd_ids) { #d_export is my list of subject
  #for (a in c("d", "b"))
  # index <- index + 1
  #print(subj)
  d_subj <- filter(rp2, PartID==subj)
  subj_model <- lm(formula=On ~ trial, #complettion time(On/Off) ~trial
                    data = d_subj)
  b_list[subj] <- as.numeric(subj_model$coefficients[1]) # coefficient intercept
  m_list[subj] <- as.numeric(subj_model$coefficients[2]) # coefficient slope

}

#Off Slopes
d_glm_fit_list <- vector(mode = "list", length = nrow(rp)*2)
index <- 0

abcd_ids=unique(rp$PartID)
b_list2=c()
m_list2 = c()

for (subj in abcd_ids) { #d_export is my list of subject
  #for (a in c("d", "b"))
  # index <- index + 1
  #print(subj)
  d_subj <- dplyr::filter(rp2, PartID==subj)
  subj_model <- lm(formula=Off ~ poly(trial,3,raw=TRUE), #complettion time(On/Off) ~trial
                    data = d_subj)
  b_list2[subj] <- as.numeric(subj_model$coefficients[1]) # coefficient intercept
  m_list2[subj] <- as.numeric(subj_model$coefficients[2]) # coefficient slope

}

#PropOn Slopes

d_glm_fit_list <- vector(mode = "list", length = nrow(rp)*2)
index <- 0

abcd_ids=unique(rp$PartID)
b_list4=c()
m_list4 = c()

for (subj in abcd_ids) { #d_export is my list of subject
  #for (a in c("d", "b"))
  # index <- index + 1
  #print(subj)
  d_subj <- filter(rp2, PartID==subj)
  subj_model <- lm(formula=prop_on ~ trial, #complettion time(On/Off) ~trial
                    data = d_subj)
  b_list4[subj] <- as.numeric(subj_model$coefficients[1]) # coefficient intercept
  m_list4[subj] <- as.numeric(subj_model$coefficients[2]) # coefficient slope
}

#Create a new Data Frame containing the slopes
rp_data <- data.frame(PartID=abcd_ids,slopeOn = m_list, slopeOff = m_list2, slopeProp_On = m_list4)
d_rp<-merge(d,rp_data,all=TRUE) 
#names(d_rp)
```

#No outliers for RP
```{r, echo=FALSE,include=FALSE, warning = FALSE}
hist(rp_data$slopeProp_On)
# calculate mean and standard deviation
mean_val <- mean(rp_data$slopeProp_On, na.rm = TRUE)
sd_val <- sd(rp_data$slopeProp_On, na.rm = TRUE)

# identify outliers (more than 3 standard deviations away from the mean)
outliers <- which(rp_data$slopeProp_On < (mean_val - 3 * sd_val) | rp_data$slopeProp_On > (mean_val + 3 * sd_val))

# remove outliers
rp_data$slopeProp_On[outliers] <- NA
```

#### ANCOVA on individual RP slopes

- No significant group effect on slope
- Should we control for IQ?

```{r, echo=FALSE,warning = FALSE}
m2<-lm(slopeProp_On~Sex+Age+kbit_ss+Subgroup, data=d_rp)
summary(m2)
lsmeans(m2, list(pairwise ~ Subgroup), adjust = "tukey") 
```

#### Plotting RP Slope Effects
```{r, echo=FALSE,warning = FALSE}
plot_rp_slope<-d_rp%>%dplyr::select('PartID',"Subgroup","slopeProp_On")
plot_rp_slope<-na.omit(plot_rp_slope)

rp_slope = plot_rp_slope %>%
  dplyr::group_by(PartID, Subgroup) %>%
  dplyr::summarise(mean = mean(slopeProp_On, na.rm = T))


multi.group3 <-
  rp_slope %>%
  dabestr::dabest(Subgroup,mean,
         idx = list(c("TYP",'DD')),
         paired = FALSE)
two.group.unpaired.meandiff <- dabestr::cohens_d(multi.group3)
plot(two.group.unpaired.meandiff, palette=c("blue","red"),rawplot.ylabel = "RP Prop On Slope")
```
\newpage

# Mirror Tracing

```{r, include=FALSE,warning = FALSE}
## Extract and organize
#PL<-d[c(1,188,3:4,54:70,71:80)]

mt <- NULL
mt <- data.frame('PartID'= character(),'Subgroup' = character(),'Type' = character(),'trial' = double(),
                     'time' = double(),'error' = double(),stringsAsFactors=FALSE)
for (i in 1:nrow(PL)) {
  if (PL[i,22] == ""){ #if null go to next line
    next()
  }
  for(k in 22:31){
    print(paste(k,PL[i,k]))
    time <- as.numeric(trimws(strsplit(PL[i,k],';')[[1]][1]))
    error <- as.numeric(trimws(strsplit(PL[i,k],';')[[1]][2]))
    if (nrow(mt) == 0) {
      mt[1,] <- c(PL[i,1],PL[i,2],'mt',k-21,time,error)
    }
    else {
      mt[nrow(mt) + 1,] <- c(PL[i,1],PL[i,2],'mt',k-21,time,error)
    }
  }
}

mt$time <- as.numeric(mt$time)
mt$error <- as.numeric(mt$error)
mt$trial <- as.numeric(mt$trial)
```

#### MT Realiability ####
```{r,echo=FALSE,warning = FALSE}
mt3<-mt%>%ungroup%>%dplyr::select(PartID,time,trial)
mt4<-mt%>%ungroup%>%dplyr::select(PartID,error,trial)

mt_t_w<- spread(mt3, trial, time)
mt_e_w<- spread(mt4, trial, error)
mt_t_w<-dplyr::select(mt_t_w,-PartID)
mt_e_w<-dplyr::select(mt_e_w,-PartID)
psych::alpha(mt_t_w)
psych::alpha(mt_e_w)


```

```{r,include=FALSE, warning=FALSE}

# Check # of trials per each subject
data_tmp4check <- aggregate(error ~ PartID * Subgroup, FUN=NROW, data = mt )
unique(data_tmp4check[data_tmp4check$trial != 10,])
#View(data_tmp4check)
length(unique(d$PartID))
data_tmp4check[data_tmp4check$trial !=10,1]

# Outliers (no 3sd outliers)
summary(mt)
mt2<-mt #place holder while deciding on outliers
mt2<-mt2%>%filter(error<95) #3sd above mean
length(unique(mt$PartID))
length(unique(mt2$PartID))
histogram(mt2$error)
#mt2<-mt2%>%filter(time<73.51465)
histogram(mt2$time)
mt2$Subgroup<-as.factor(mt2$Subgroup)

```

### Statistical Analysis by Trial

#### Baseline differences on trial one
```{r, echo=FALSE,include=FALSE, warning = FALSE}
mt2$Subgroup<-as.factor(mt2$Subgroup)
mt2 = merge(mt2,d[,c(1,3,4,6)],all.x=TRUE)

#extract trial 1
mt_1<-mt2%>%
  dplyr::filter(trial==1)
me_1<-mt2%>%
  dplyr::filter(trial==1)

```

- No significant group differences on first trial
```{r,warning = FALSE}
mtri1<-lm(error~Age+Sex+kbit_ss+Subgroup,data=me_1)
anova(mtri1)
effectsize::eta_squared(mtri1)
t.test(error~Subgroup,data=me_1)
mtri2<-lm(time~Age+Sex+kbit_ss+Subgroup,data=mt_1)
anova(mtri2)
#eta_sq(mtri2)

t.test(time~Subgroup,data=mt_1)
```

### Linear mixed modeling
- Filtered out first trial
- Main effect of trial, no significant effect of subgroup on time or error
```{r, echo=FALSE,warning = FALSE,include=FALSE}
mt1<-mt2
mt2<-mt2%>%filter(trial!=1) #exclude trial 1
#mt2$PartID<-as.factor(mt2$PartID)
mt2_age_gender_iq = merge(mt2,d[,c(1,3,4,6)],all.x=TRUE)

lmerm1<-lmer(time~Age+Sex+kbit_ss+Subgroup*trial+(1+trial|PartID),
        data=mt2_age_gender_iq)
lmerm2<-lmer(time~Age+Sex+kbit_ss+Subgroup*trial+(1|PartID),
        data=mt2_age_gender_iq)
#lmerm3<-lmer(time~Age+Sex+kbit_ss+Subgroup*trial+(1|trial),
        #data=mt2_age_gender_iq)
anova(lmerm1,lmerm2)
#anova(lmerm1,lmerm3)
summary(lmerm1)
anova(lmerm1)
r2beta(lmerm1, method = "nsj")
```

```{r, echo=FALSE,warning = FALSE,include=FALSE}
lmerm4<-lmer(error~Age+Sex+kbit_ss+Subgroup*trial+(1+trial|PartID),
        data=mt2_age_gender_iq)
lmerm5<-lmer(error~Age+Sex+kbit_ss+Subgroup*trial+(1|PartID),
        data=mt2_age_gender_iq)
#lmerm6<-lmer(error~Age+Sex+kbit_ss+Subgroup*trial+(1|trial),
        #data=mt2_age_gender_iq)
anova(lmerm4,lmerm5)
#anova(lmerm4,lmerm6)
anova(lmerm4)
 r2beta(lmerm4, method = "nsj")
summary(lmerm4)
```

## MT: Plot Time/Error by Trial

```{r, echo=FALSE,warning = FALSE}
mt2<-mt
mt2<-mt2%>%filter(trial!=1)

mt2$time <- as.numeric(mt2$time)
mt2$error <- as.numeric(mt2$error)
mt2$trial <- as.numeric(mt2$trial)

mtTPlot<-dplyr::summarise(group_by(mt2,Subgroup,trial), n = n(),
                         meanT=mean(time,na.rm = T), sd=sd(time,na.rm = T),se = sd/sqrt(n))
mtEPlot<-dplyr::summarise(group_by(mt2,Subgroup,trial), n = n(),
                          meanE=mean(error,na.rm = T), sd=sd(error,na.rm = T),se = sd/sqrt(n))


mt_t<-ggplot(data = mtTPlot, aes(x=trial, y=meanT, color = Subgroup))+
  geom_line(size=1.5) +geom_point(size=2)  +
  scale_color_manual(values=c('#00BDD0','#E7861B'))+
  geom_errorbar(aes(ymin=meanT-se,ymax=meanT+se),
                 width=.2,  size=0.5)+
  scale_x_continuous(breaks=seq(1,16,1))+
  #scale_y_continuous(limits = c(0.2, 0.5))+
  theme(
    axis.title = element_text(family = "Times New Roman", size = 20),
    legend.key.size = unit(1, "cm"),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15))  +
  labs(x = "Trials", y = "Completion Time (secs)") +
  theme(panel.background = element_rect(fill = "white", colour = "grey50"),text=element_text(size=16,family="Times New Roman"),legend.key.size = unit(0.8, "cm"),
    legend.text = element_text(
      size = 16,
      face = 'bold'
    ),
    legend.title = element_blank(),)+
  theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))

mt_t2<-mt_t + theme(legend.position = "none")
ggsave("mt_t011222.png",width=6, height=4)

```


```{r, echo=FALSE,warning = FALSE}
mt_e<-ggplot(data = mtEPlot, aes(x=trial, y=meanE, color = Subgroup))+
  geom_line(size=1.5) +geom_point(size=2)  +
  scale_color_manual(values=c('#00BDD0','#E7861B'))+
  geom_errorbar(aes(ymin=meanE-se,ymax=meanE+se),
                width=.2,  size=0.5)+
  scale_x_continuous(breaks=seq(0,10,1))+
  #scale_y_continuous(limits = c(0.2, 0.5))+
   theme(
    axis.title = element_text(family = "Times New Roman", size = 20),
    legend.key.size = unit(1, "cm"),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15))  +
  labs(x = "Trials", y = "Number of Errors") +
  theme(panel.background = element_rect(fill = "white", colour = "grey50"),text=element_text(size=16,family="Times New Roman"),legend.key.size = unit(0.8, "cm"),
    legend.text = element_text(
      size = 16,
      face = 'bold'
    ),
    legend.title = element_blank(),)+
  theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))

mt_e2<-mt_e + theme(legend.position = "none")
ggsave("mt_e011222.png",width=6, height=4)
```

### Mirror Tracing Slopes
####Error Slopes
```{r, echo=FALSE,warning = FALSE,include=FALSE}

mt3<-na.omit(mt2%>%filter(trial>2))
d_glm_fit_list <- vector(mode = "list", length = nrow(mt)*2)
index <- 0
abcd_ids=unique(mt3$PartID)
b_list5=c()
m_list5 = c()

for (subj in abcd_ids) {
 # print(subj)
  d_subj <- filter(mt3, PartID==subj)
  subj_model <- lm(error ~ trial, #errors
                    data = d_subj)
  b_list5[subj] <- as.numeric(subj_model$coefficients[1]) # coefficient intercept
  m_list5[subj] <- as.numeric(subj_model$coefficients[2]) # coefficient slope
}


```

####Time Slopes
```{r, echo=FALSE,warning = FALSE,include=FALSE}
d_glm_fit_list <- vector(mode = "list", length = nrow(mt)*2)
index <- 0
abcd_ids=unique(mt3$PartID)
b_list7=c()
m_list7 = c()

for (subj in abcd_ids) {
 print(subj)
  d_subj <- filter(mt3, PartID==subj)
  subj_model <- lm(time ~ trial, #errors
                    data = d_subj)
  b_list7[subj] <- as.numeric(subj_model$coefficients[1]) # coefficient intercept
  m_list7[subj] <- as.numeric(subj_model$coefficients[2]) # coefficient slope
}


#new data frame containing the mirror slopes
mt_data <- data.frame(PartID=abcd_ids,slope_me = m_list5, slope_mt = m_list7)
mt_data$slope_me<-as.numeric(mt_data$slope_me)
mt_data$slope_mt<-as.numeric(mt_data$slope_mt)


# remove outliers
# Calculate mean and standard deviation of slope_mt variable
mean_slope_mt <- mean(mt_data$slope_mt, na.rm = TRUE)
sd_slope_mt <- sd(mt_data$slope_mt, na.rm = TRUE)
mean_slope_me <- mean(mt_data$slope_me, na.rm = TRUE)
sd_slope_me <- sd(mt_data$slope_me, na.rm = TRUE)

# Identify outliers (values that are 3 standard deviations below or above the mean)
outliers_mt <- which(mt_data$slope_mt < mean_slope_mt - 3*sd_slope_mt | mt_data$slope_mt > mean_slope_mt + 3*sd_slope_mt)

outliers_me <- which(mt_data$slope_me < mean_slope_me - 3*sd_slope_me | mt_data$slope_me > mean_slope_me + 3*sd_slope_me)



# remove outliers from dataset
mt_data_clean <- mt_data[-outliers_me, ] #removed one outlier
outliers <- mt_data[outliers_me, ] #removed one outlier

```

## Final DF with PL
```{r, echo=FALSE,warning = FALSE}
d_3 <- d %>%
   dplyr::select("PartID","Subgroup", "Age","Sex","IQ","Elision",'Blending','WID','WA')

d_mt <- merge(mt_data_clean, d_3, all=TRUE)
d2<-merge(rp_data,d_mt,all = TRUE)
table(d2$Subgroup)
```

##### MT Slope analysis
- A significant group effects for slope, with faster learning for Typ, even after controlling for age, sex, and IQ.
- Removed participants with slopes above zero (opposite learning pattern-N=2)

```{r, echo=FALSE,warning = FALSE}
m3<-lm(slope_mt~Age+Sex+kbit_ss+Subgroup, data=d2,na.action = na.exclude)
summary(m3)
lsmeans(m3, list(pairwise ~ Subgroup), adjust = "tukey")
m4<-lm(slope_me~Age+Sex+kbit_ss+Subgroup, data=d2,na.action = na.exclude)
summary(m4)
lsmeans(m4, list(pairwise ~ Subgroup), adjust = "tukey")
```

## MT: Plot Slope Effects

```{r, echo=FALSE,warning = FALSE}

mt_slope<-d2%>%dplyr::select("PartID","Subgroup","slope_mt")
mt_slope$Subgroup<-as.factor(mt_slope$Subgroup)

mt_slope2<-mt_slope%>%dplyr::select('PartID',"Subgroup","slope_mt")
mt_slope2<-na.omit(mt_slope2)

multi.group_mt = mt_slope2 %>%
  dplyr::group_by(PartID, Subgroup) %>%
  dplyr::summarise(mean = mean(slope_mt, na.rm = T))


multi.group_mt <-
  multi.group_mt %>%
  dabestr::dabest(Subgroup,mean,
         idx = list(c("TYP",'DD')),
         paired = FALSE)
two.group.unpaired.meandiff_mt <- dabestr::cohens_d(multi.group_mt)

plot(two.group.unpaired.meandiff_mt, palette=c("blue","red"),rawplot.ylabel = "MT Time Slope")
```


```{r, echo=FALSE,warning = FALSE}
me_slope<-d2%>%dplyr::select("PartID","Subgroup","slope_me")

me_slope2<-na.omit(me_slope)

multi.group_me = me_slope2 %>%
  dplyr::group_by(PartID, Subgroup) %>%
  dplyr::summarise(mean = mean(slope_me, na.rm = T))


multi.group_me <-
  multi.group_me %>%
  dabestr::dabest(Subgroup,mean,
         idx = list(c("TYP",'DD')),
         paired = FALSE)
two.group.unpaired.meandiff_me <- dabestr::cohens_d(multi.group_me)

plot(two.group.unpaired.meandiff_me, palette=c("blue","red"),rawplot.ylabel = "MT Error Slope")
```
\newpage

# Create a MASTER df
```{r, echo=FALSE,warning = FALSE}
names(SL)[names(SL) == "subj"] <- "PartID"
d_all<-merge(d2,SL,all = TRUE)
d_all$PA <- rowMeans(d_all[, c('Elision', 'Blending')], na.rm = TRUE)
d_all$WR<-rowMeans(d_all[,c('WID','WA')], na.rm = TRUE)
write.csv(d_all,"FINAL_learning_df_050423.csv")
```

# Statistical Learning
```{r,echo=FALSE,warning = FALSE, include=FALSE}
subj_table_vsl<-read.csv("sl_analysis/vsl_rt_subj_table.csv")
fam_trial_vsl<-read.csv("sl_analysis/vsl_rt_trial.csv")
fam_trial_vsl_scale<-read.csv("sl_analysis/vsl_rt_scale_trial.csv")
subj_table_tsl<-read.csv("sl_analysis/tsl_rt_subj_table.csv")
fam_trial_tsl<-read.csv("sl_analysis/tsl_rt_trial.csv")
fam_trial_tsl_scale<-read.csv("sl_analysis/tsl_rt_scale_trial.csv")

#need to rename from Subj  to PartID
names(subj_table_vsl)[names(subj_table_vsl)=="subj"] <- "PartID"
names(fam_trial_vsl)[names(fam_trial_vsl)=="subj"] <- "PartID"
names(fam_trial_vsl_scale)[names(fam_trial_vsl_scale)=="subj"] <- "PartID"
names(subj_table_tsl)[names(subj_table_tsl)=="subj"] <- "PartID"
names(fam_trial_tsl)[names(fam_trial_tsl)=="subj"] <- "PartID"
names(fam_trial_tsl_scale)[names(fam_trial_tsl_scale)=="subj"] <- "PartID"


```

```{r, echo=FALSE,warning = FALSE,include=FALSE}
data<-as_tibble(subj_table_tsl)
data %>%
  group_by(Subgroup) %>%
  dplyr::summarise(
          count = n(),
          rt = qwraps2::mean_sd(mean_rt),
          slope = qwraps2::mean_sd(rt_slope),
          d_prime = qwraps2::mean_sd(dprime),
          hits = qwraps2::mean_sd(hit_rate)
          )
```

- remove outliers who have hit rate lower than and equal to 0.25 (remaining participant: 14 DD and 18 TYP)
- participants removed from analysis: ABCD_1705 ABCD_1720 ABCD_1747 ABCD_1767 ABCD_1783 ABCD_1788 ABCD_1709 ABCD_1724
- [4/19/23: per R1's comment, keep all ASL data - participants removed from analysis: ABCD_1705 ABCD_1720 ABCD_1747 ABCD_1767 ABCD_1783 ABCD_1788 ABCD_1709 ABCD_1724]


```{r,echo=FALSE,warning=FALSE,include=FALSE}
usable_tsl_rt<-subj_table_tsl[subj_table_tsl$hit_rate>0,]$PartID
subj_table_tsl_usable <-subset(subj_table_tsl,PartID %in% usable_tsl_rt)
data<-as_tibble(subj_table_tsl_usable)
data %>%
  group_by(Subgroup) %>%
  dplyr::summarise(
          count = n(),
          rt = qwraps2::mean_sd(mean_rt),
          slope = qwraps2::mean_sd(rt_slope),
          d_prime = qwraps2::mean_sd(dprime),
          hits = qwraps2::mean_sd(hit_rate)
          )
```

# TSL Analysis

### RT by Trial Analysis
- There is no significant group difference in baseline speed for TSL.
```{r,echo=FALSE,warning = FALSE}
t.test(subj_table_tsl_usable$mean_rt~subj_table_tsl_usable$Subgroup)
```
- There is no significant group difference in detection accuracy for TSL

```{r,echo=FALSE,warning = FALSE}
t.test(hit_rate~Subgroup,data=subj_table_tsl_usable)
```
- No RT effect of group or interaction tested either by lm or lmer
```{r,echo=FALSE,warning=FALSE}
fam_trial_tsl_usable <-subset(fam_trial_tsl,PartID %in% usable_tsl_rt)
fam_trial_tsl_usable_s <-subset(fam_trial_tsl_scale,PartID %in% usable_tsl_rt)
fam_tsl_age_gender_iq = merge(fam_trial_tsl_usable,d[,c(1,3,4,6)],all.x=TRUE)
fam_tsl_s_age_gender_iq = merge(fam_trial_tsl_usable_s,d[,c(1,3,4,6)],all.x=TRUE)
library(car)
fam_tsl_s_age_gender_iq$Subgroup = as.factor(fam_tsl_s_age_gender_iq$Subgroup)
contrasts(fam_tsl_s_age_gender_iq$Subgroup) <-contr.Sum(levels(fam_tsl_s_age_gender_iq$Subgroup))
model2_cov <- lmer(rt_col~Age+Sex+kbit_ss+reindex*Subgroup+(1+reindex|PartID),data=fam_tsl_age_gender_iq)
summary(model2_cov)
r2beta(model2_cov, method = "nsj")

```
- ANCOVA with covariates (RT slope data) - no group effect
```{r,echo=FALSE,warning = FALSE}
subj_table_tsl_gender_iq = merge(subj_table_tsl_usable,d[,c(1,3,4,6)],all.x=TRUE)
tsl_rt_ancova=lm(rt_slope~Subgroup+Age+Sex+kbit_ss,data=subj_table_tsl_gender_iq)
summary(tsl_rt_ancova)
```

#### Plot of TSL RT
- RT as the function of Target repetition
```{r,echo=FALSE}
tsl_rt_plot<-dplyr::summarise(group_by(fam_trial_tsl,Subgroup,reindex), n = n(),
                         mean=mean(rt_col,na.rm = T), sd=sd(rt_col,na.rm = T),se = sd/sqrt(n))

tsl_rt<-ggplot(data = tsl_rt_plot, aes(x=reindex, y=mean, col=Subgroup))+
  geom_line(size=1.5) +geom_point(size=2)  +
  scale_color_manual(values=c('#00BDD0','#E7861B'))+
  geom_errorbar(aes(ymin=mean-se,ymax=mean+se),
                 width=.2,  size=0.5)+
  scale_x_continuous(breaks=seq(4,48,4))+
  #scale_y_continuous(limits = c(0.2, 0.5))+
  theme(
    axis.title = element_text(family = "Trebuchet MS", size = 20),
    legend.key.size = unit(1, "cm"),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15))  +
  labs(x = "Trials", y = "Response Time (ms)") +
  theme(panel.background = element_rect(fill = "white", colour = "grey50")) +
  theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))

tsl_rt2<-tsl_rt + theme(legend.position = "none")
ggsave("tsl_rt011222.png",width=7, height=4)
```

### Plot ASL RT Slope

```{r,echo=FALSE}
asl_slope<-subj_table_tsl_usable%>%dplyr::select("PartID","Subgroup","rt_slope")

asl_slope<-na.omit(asl_slope)

asl_slope2 = asl_slope %>%
  dplyr::group_by(PartID, Subgroup) %>%
  dplyr::summarise(mean = mean(rt_slope, na.rm = T))

multi.group_asl <-
 asl_slope2 %>%
  dabestr::dabest(Subgroup,mean,
         idx = list(c("TYP","DD")),
         paired = FALSE
  )

multi.group_asl_2 <- dabestr::cohens_d(multi.group_asl)

plot(multi.group_asl_2, palette=c("blue","red"),rawplot.ylabel = "ASL Time Slope")
```

####VSL Slope Analysis
```{r,echo=FALSE,warning=FALSE}
data<-as_tibble(subj_table_vsl)
data %>%
  group_by(Subgroup) %>%
  dplyr::summarise(
          count = n(),
          rt = qwraps2::mean_sd(mean_rt),
          slope = qwraps2::mean_sd(rt_slope),
          d_prime = qwraps2::mean_sd(dprime),
          hits = qwraps2::mean_sd(hit_rate)
          ) 

```
- There is no significant group difference in baseline speed for VSL.
```{r,echo=FALSE,warning = FALSE}
t.test(subj_table_vsl$mean_rt~subj_table_vsl$Subgroup)
t.test(subj_table_vsl$hit_rate~subj_table_vsl$Subgroup)
```
- There is no significant group difference in target detection accuracy for VSL
```{r,echo=FALSE,warning = FALSE}
subj_table_vsl_iq_age = merge(data,d[,c(1,3,4,6)],all.x=TRUE)
summary(lm(dprime~Age+Sex+kbit_ss+Subgroup,data=subj_table_vsl_iq_age))
```
- The DD group had a faster RT acceleration than the TYP group (significant group x trial index interaction tested by lm and marginal interaction tested by lmer)
```{r,echo=FALSE,warning=FALSE}
fam_vsl_age_gender_iq = merge(fam_trial_vsl,d[,c(1,3,4,6)],all.x=TRUE)
fam_vsl_s_age_gender_iq = merge(fam_trial_vsl_scale,d[,c(1,3,4,6)],all.x=TRUE)
fam_vsl_s_age_gender_iq$Subgroup = as.factor(fam_vsl_s_age_gender_iq$Subgroup)
contrasts(fam_vsl_s_age_gender_iq$Subgroup) <-contr.Sum(levels(fam_vsl_s_age_gender_iq$Subgroup))
model2_cov <- lmer(rt_col~Age+Sex+kbit_ss+reindex*Subgroup+(1+reindex|PartID),data=fam_vsl_age_gender_iq)
summary(model2_cov)
r2beta(model2_cov, method = "nsj")
```
- ANCOVA with covariates (from the slope data): marginal group effect. 
```{r,echo=FALSE,warning = FALSE}
subj_table_vsl_gender_iq = merge(subj_table_vsl,d[,c(1,3,4,6)],all.x=TRUE)
vsl_rt_ancova=aov(rt_slope~Subgroup+Age+Sex+kbit_ss,data=subj_table_vsl_gender_iq)
summary(vsl_rt_ancova)
```
- within DYS group 
```{r,echo=FALSE,warning = FALSE}
model2_DYS <- lmer(rt_col~Age+Sex+kbit_ss+reindex+(1+reindex|PartID),data=fam_vsl_age_gender_iq[fam_vsl_age_gender_iq$Subgroup=="DD",])
summary(model2_DYS)
```
- within TYP group 
```{r,echo=FALSE,warning = FALSE}
model2_TYP <- lmer(rt_col~Age+Sex+kbit_ss+reindex+(1+reindex|PartID),data=fam_vsl_age_gender_iq[fam_vsl_age_gender_iq$Subgroup=="TYP",])
summary(model2_TYP)
```
####Plot of VSL RT

- RT as the function of Target repetition
```{r,echo=FALSE}
vsl_rt_plot<-dplyr::summarise(group_by(fam_trial_vsl,Subgroup,reindex), n = n(),
                         mean=mean(rt_col,na.rm = T), sd=sd(rt_col,na.rm = T),se = sd/sqrt(n))

vsl_rt<-ggplot(data = vsl_rt_plot, aes(x=reindex, y=mean, color = Subgroup))+
  geom_line(size=1.5) +geom_point(size=2)  +
  scale_color_manual(values=c('#00BDD0','#E7861B'))+
  geom_errorbar(aes(ymin=mean-se,ymax=mean+se),
                 width=.2,  size=0.5)+
  scale_x_continuous(breaks=seq(2,24,2))+
  #scale_y_continuous(limits = c(0.2, 0.5))+
  theme(
    axis.title = element_text(family = "Trebuchet MS", size = 20),
    legend.key.size = unit(1, "cm"),
    axis.text.x = element_text(size = 15),
    axis.text.y = element_text(size = 15))  +
  labs(x = "Trials", y = "Response Time (ms)") +
  theme(panel.background = element_rect(fill = "white", colour = "grey50")) +
  theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))
vsl_rt2<-vsl_rt + theme(legend.position = "none")
ggsave("vsl_rt011222.png",width=7, height=4)
```
#### plot mean RT slope across the two groups

```{r, echo=FALSE,warning = FALSE}
vsl_slope<-subj_table_vsl%>%dplyr::select("PartID","Subgroup","rt_slope")

vsl_slope<-na.omit(vsl_slope)

vsl_slope2 = vsl_slope %>%
  dplyr::group_by(PartID, Subgroup) %>%
  dplyr::summarise(mean = mean(rt_slope, na.rm = T))

multi.group_vsl <-
 vsl_slope2 %>%
  dabestr::dabest(Subgroup,mean,
         idx = list(c("TYP","DD")),
         paired = FALSE
  )

multi.group_vsl_2 <- dabestr::cohens_d(multi.group_vsl)

plot(multi.group_vsl_2, palette=c("blue","red"),rawplot.ylabel = "VSL Slope")
```

#### Combine slope data of both tasks

```{r,echo=FALSE,warning=FALSE,include=FALSE}
colnames(subj_table_tsl_usable)[1]="subj"
colnames(subj_table_vsl)[1]="subj"
subj_table_tsl_usable$task = "Auditory"
subj_table_vsl$task = "Visual"
all_subj_slope = rbind(subj_table_vsl,subj_table_tsl_usable)
fam_trial_vsl_scale$task="Visual"
fam_trial_tsl_usable_s$task="Auditory"
all_fam_trials = rbind(fam_trial_vsl_scale,fam_trial_tsl_usable_s)
```

#### Using scaled RT, check interactions between task and group. 

- both lm and lmer models: task x trial interaction: visual task show faster acceleration across the two groups; task x trial x group interaction (marginal): group difference in slope is greater in VSL than ASL
```{r,echo=FALSE,warning=FALSE}
all_subj_slope$tasknum=""
for (id in all_subj_slope$subj) {
  all_subj_slope[all_subj_slope$subj==id,]$tasknum = nrow(all_subj_slope[all_subj_slope$subj==id,])
}
all_subj_slope_complete = subset(all_subj_slope,tasknum==2)
all_subj_slope_age_gender_iq = merge(all_subj_slope_complete,d[,c(1,3,4,6)],all.x=TRUE)
all_fam_trials_age_gender_iq = merge(all_fam_trials,d[,c(1,3,4,6)],all.x=TRUE)
all_fam_trials_age_gender_iq$task = as.factor(all_fam_trials_age_gender_iq$task)
all_fam_trials_age_gender_iq$Subgroup = as.factor(all_fam_trials_age_gender_iq$Subgroup)
contrasts(all_fam_trials_age_gender_iq$task) <-contr.Sum(levels(all_fam_trials_age_gender_iq$task))
contrasts(all_fam_trials_age_gender_iq$Subgroup) <-contr.Sum(levels(all_fam_trials_age_gender_iq$Subgroup))
model_rt_lmer_cov <- lmer(rt_col~Age+Sex+kbit_ss+task*reindex*Subgroup+(1+task|PartID)+(task|reindex),data=all_fam_trials_age_gender_iq)
print(summary(model_rt_lmer_cov))

typ_fam_trials_age_gender_iq = subset(all_fam_trials_age_gender_iq, Subgroup == "TYP")
model_rt_lmer_cov_typ <- lmer(rt_col~Age+Sex+kbit_ss+task*reindex+(1+task|PartID)+(task|reindex),data=typ_fam_trials_age_gender_iq)
print(summary(model_rt_lmer_cov_typ))
r2beta(model_rt_lmer_cov_typ, method = "nsj")
```
- ANCOVA for interaction between task and group (no significant interaction)
```{r,echo=FALSE,warning = FALSE}
all_sl_slope_ancova = lm(rt_slope_scale~Subgroup*task+Age+Sex+kbit_ss,data=all_subj_slope_age_gender_iq)
print(summary(all_sl_slope_ancova))
```

## SL Accuracy Analysis

#### Accuracy Data Summary (mean +/- sd)
```{r,echo=FALSE,warning=FALSE}
all_accuracy=read.csv("sl_analysis/all_sl_accuracy.csv")
all_acc_table=read.csv("sl_analysis/sl_acc_subj_table.csv")
vsl_acc_table=subset(all_acc_table,task=="Visual")
tsl_acc_table=subset(all_acc_table,task=="Auditory")
vsl_accuracy=subset(all_accuracy,task=="Visual")
tsl_accuracy=subset(all_accuracy,task=="Auditory")
data<-as_tibble(all_acc_table)
data %>%
  group_by(Subgroup,task) %>%
  dplyr::summarise(
          count = n(),
          accuracy = qwraps2::mean_sd(subj_corr)
          )
```
#### ASL and VSL Accuracy 
- both groups performed above chance for both tasks
```{r,echo=FALSE,warning=FALSE}
DD_acc_vsl = subset(vsl_acc_table,Subgroup=="DD")
TYP_acc_vsl = subset(vsl_acc_table,Subgroup=="TYP")
DD_acc_tsl = subset(tsl_acc_table,Subgroup=="DD")
TYP_acc_tsl = subset(tsl_acc_table,Subgroup=="TYP")
t.test(DD_acc_vsl$subj_corr,mu=0.5,alternative = "greater")
t.test(DD_acc_tsl$subj_corr,mu=0.5,alternative = "greater")

t.test(TYP_acc_vsl$subj_corr,mu=0.5,alternative = "greater")
t.test(TYP_acc_tsl$subj_corr,mu=0.5,alternative = "greater")
```


```{r,echo=FALSE}
vsl_accuracy = subset(all_accuracy,task=="Visual")
tsl_accuracy = subset(all_accuracy,task=="Auditory")

vsl_accuracy_age_gender_iq = merge(vsl_accuracy,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
tsl_accuracy_age_gender_iq = merge(tsl_accuracy,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
```
- generalized linear effect modeling within each task (both models failed to converge with IQ included, removing IQ from the covariates fix the issues)
-  VSL, no group effect
```{r,echo=FALSE}
vsl_accuracy_age_gender_iq$Subgroup =as.factor(vsl_accuracy_age_gender_iq$Subgroup)
contrasts(vsl_accuracy_age_gender_iq$Subgroup) <-contr.Sum(levels(vsl_accuracy_age_gender_iq$Subgroup))

model_vslacc_lmer_cov <- glmmPQL(corr~Age+Sex+kbit_ss+Subgroup,random=~1|PartID/trial,data=vsl_accuracy_age_gender_iq,family="binomial")
print(summary(model_vslacc_lmer_cov))
r2beta(model_vslacc_lmer_cov,method="sgv")
```
```{r,echo=FALSE, include=FALSE}
all_acc_table_age_gender_iq = merge(all_acc_table,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
vsl_acc_table = subset(all_acc_table_age_gender_iq,task == "Visual")
asl_acc_table = subset(all_acc_table_age_gender_iq,task == "Auditory")
#vslacc_ancova <- aov(subj_corr~Age+Sex+IQ+Subgroup,data=vsl_acc_table)
#print(summary(vslacc_ancova))
```
- Significant group effects for ASL (Typ>Dys)
```{r,echo=FALSE}
tsl_accuracy_age_gender_iq$Subgroup =as.factor(tsl_accuracy_age_gender_iq$Subgroup)
contrasts(tsl_accuracy_age_gender_iq$Subgroup) <-contr.Sum(levels(tsl_accuracy_age_gender_iq$Subgroup))

model_tslacc_lmer_cov <- glmmPQL(corr~Age+Sex+kbit_ss+Subgroup,random=~1|PartID/trial,data=tsl_accuracy_age_gender_iq,family="binomial")
print(summary(model_tslacc_lmer_cov))
r2beta(model_tslacc_lmer_cov,method="sgv")
```
```{r,echo=FALSE, include=FALSE}
#aslacc_ancova <- aov(subj_corr~Age+Sex+IQ+Subgroup,data=asl_acc_table)
#print(summary(aslacc_ancova))
```

#### Plot VSL Accuracy

```{r,echo=FALSE}
vsl_acc_summary = vsl_acc_table %>%
  dplyr::group_by(PartID, Subgroup) %>%
  dplyr::summarise(mean = mean(subj_corr, na.rm = T))

multi.group_vsl_acc <-
 vsl_acc_summary %>%
  dabestr::dabest(Subgroup,mean,
         idx = list(c("TYP","DD")),
         paired = FALSE
  )

multi.group_vsl_acc_2 <- dabestr::cohens_d(multi.group_vsl_acc)

plot(multi.group_vsl_acc_2, palette=c("blue","red"),rawplot.ylabel = "VSL Accuracy")
```
#### Plot ASL Accuracy

```{r,echo=FALSE}
tsl_acc_summary = tsl_acc_table %>%
  dplyr::group_by(PartID, Subgroup) %>%
  dplyr::summarise(mean = mean(subj_corr, na.rm = T))

multi.group_tsl_acc <-
 tsl_acc_summary %>%
  dabestr::dabest(Subgroup,mean,
         idx = list(c("TYP","DD")),
         paired = FALSE
  )

multi.group_tsl_acc_2 <- dabestr::cohens_d(multi.group_tsl_acc)

plot(multi.group_tsl_acc_2, palette=c("blue","red"),rawplot.ylabel = "ASL Accuracy")
```

#### Task by Group Interaction

- LME: main effect of task (visual > auditory); main effect of group (TYP > DD); 
```{r,echo=FALSE}
all_accuracy_age_gender_iq = merge(all_accuracy,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
all_accuracy_age_gender_iq$task = as.factor(all_accuracy_age_gender_iq$task)
all_accuracy_age_gender_iq$Subgroup = as.factor(all_accuracy_age_gender_iq$Subgroup)
contrasts(all_accuracy_age_gender_iq$task) <-contr.Sum(levels(all_accuracy_age_gender_iq$task))
contrasts(all_accuracy_age_gender_iq$Subgroup) <-contr.Sum(levels(all_accuracy_age_gender_iq$Subgroup))
all_accuracy_age_gender_iq_typ = subset(all_accuracy_age_gender_iq,Subgroup=="TYP")
model_acc_lmer <- glmmPQL(corr~task*Subgroup+Age+Sex,random = ~1|PartID/trial/task,data=all_accuracy_age_gender_iq,family="binomial")
print(summary(model_acc_lmer))
r2beta(model_acc_lmer,method="sgv")
model_acc_lmer_typ <- glmmPQL(corr~task+Age+Sex,random = ~1|PartID/trial/task,data=all_accuracy_age_gender_iq_typ,family="binomial")
print(summary(model_acc_lmer_typ))
r2beta(model_acc_lmer_typ,method="sgv")
```

- ANCOVA: marginal effect of task (Visual > Auditory)
```{r,echo=FALSE,warning=FALSE}
all_acc_table_complete = subset(all_acc_table,PartID!="ABCD_1708")
all_acc_table_complete = subset(all_acc_table_complete,PartID!="ABCD_1727")
all_acc_table_age_gender_iq = merge(all_acc_table_complete,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
model_acc <- lm(subj_corr~task*Subgroup+Age+Sex+kbit_ss,data=all_acc_table_age_gender_iq)
print(summary(model_acc))
```

#### Plot  accuracy by group and task
```{r,echo=FALSE}
stat.test <- all_acc_table %>%
  group_by(task) %>%
  tukey_hsd(subj_corr~Subgroup)
stat.test
stat.test <- stat.test %>% add_xy_position(x = "group", fun = "mean_se")
all_acc_table$Subgroup = as.factor(all_acc_table$Subgroup)
#cbbPalette <- c("#00BDD0","#E7861B")
ggplot() +
  geom_bar(aes(x = Subgroup,y = subj_corr,fill = Subgroup),data=all_acc_table,colour = '#000000',fun.data = mean_sdl,fun.args = list(mult = 1),stat = 'summary',position = position_dodge(width = 0.9)) +
  #scale_fill_manual("legend", values = c("DD" = "#00BDD0", "TYP" = "#E7861B"))+
  scale_fill_manual("legend", values = c("DD" = "grey73", "TYP" = "grey86"))+
  theme_classic(base_size = 18.0) +
  ylab(label = '% Correct') +
  xlab(label = 'Group') +
  #coord_cartesian(ylim = c(0.3,1)) +
  geom_errorbar(aes(y = subj_corr, x = Subgroup),data=all_acc_table,size = 0.3,width = 0.2,fun.y = function(x) mean(x),fun.ymin = function(x) mean(x) - sd(x)/sqrt(length(x)),fun.ymax = function(x) mean(x) + sd(x)/sqrt(length(x)) ,stat = 'summary')+
  geom_beeswarm(aes(x = Subgroup,y = subj_corr, colour = Subgroup),data=all_acc_table,dodge.width=1,cex=3.5) +
  facet_wrap(task~.) +
  scale_color_manual(values=c('black','black'))
```
#### VSL reliability
```{r,include=FALSE,warning = FALSE}
d <- matrix(nrow=40,ncol=32)
for(i in seq(from=1,to=40,by=1)){d[i,] <- rbind(vsl_accuracy$corr[((i-1)*32+1):(i*32)])}
psych::alpha(d,check.keys = TRUE)$total$std.alpha

vsl_rt <- subset(fam_trial_vsl,select=c(4,3,6))
vsl_rt_w<- spread(vsl_rt, reindex, rt_col)
vsl_rt_w<-dplyr::select(vsl_rt_w,-PartID)
psych::alpha(vsl_rt_w,check.keys = TRUE)$total$std.alpha
```
#### ASL reliability
```{r,include=FALSE,warning = FALSE}
d <- matrix(nrow=40,ncol=32)
for(i in seq(from=1,to=40,by=1)){d[i,] <- rbind(tsl_accuracy$corr[((i-1)*32+1):(i*32)])}
psych::alpha(d,check.keys = TRUE)$total$std.alpha

asl_rt <- subset(fam_trial_tsl_usable,select=c(4,3,6))
asl_rt_w<- spread(asl_rt, reindex, rt_col)
asl_rt_w<-dplyr::select(asl_rt_w,-PartID)
psych::alpha(asl_rt_w,check.keys = TRUE)$total$std.alpha
```

# Cross-task correlations

```{r,include=FALSE,warning = FALSE}
d_all$PA<-rowMeans(d_all[,c('Elision','Blending')])
d_all$WR<-rowMeans(d_all[,c('WID','WA')])

d_all_dys = subset(d_all,Subgroup == "DD")
d_all_typ = subset(d_all,Subgroup == "TYP")

task_data<-d_all%>%ungroup%>%dplyr::select(WR,PA,SWE,PDE,WID,WA, gort_rate_ss, gort_accuracy_ss, gort_fluency_ss, slopeProp_On,slope_mt,slope_me,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale,IQ,Age)%>%dplyr::filter_at(vars(IQ), all_vars(!is.na(.)))
task_data$gort_rate_ss=as.numeric(as.character(task_data$gort_rate_ss))
task_data$gort_accuracy_ss=as.numeric(as.character(task_data$gort_accuracy_ss))
task_data$gort_fluency_ss=as.numeric(as.character(task_data$gort_fluency_ss))

task_data_dys<-d_all_dys%>%ungroup%>%dplyr::select(WR,PA,SWE,PDE,WID,WA, gort_rate_ss, gort_accuracy_ss, gort_fluency_ss, slopeProp_On,slope_mt,slope_me,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale,IQ,Age)%>%dplyr::filter_at(vars(IQ), all_vars(!is.na(.)))
task_data_dys$gort_rate_ss=as.numeric(as.character(task_data_dys$gort_rate_ss))
task_data_dys$gort_accuracy_ss=as.numeric(as.character(task_data_dys$gort_accuracy_ss))
task_data_dys$gort_fluency_ss=as.numeric(as.character(task_data_dys$gort_fluency_ss))

task_data_typ<-d_all_typ%>%ungroup%>%dplyr::select(WR,PA,SWE,PDE,WID,WA, gort_rate_ss, gort_accuracy_ss, gort_fluency_ss, slopeProp_On,slope_mt,slope_me,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale,IQ,Age)%>%dplyr::filter_at(vars(IQ), all_vars(!is.na(.)))
task_data_typ$gort_rate_ss=as.numeric(as.character(task_data_typ$gort_rate_ss))
task_data_typ$gort_accuracy_ss=as.numeric(as.character(task_data_typ$gort_accuracy_ss))
task_data_typ$gort_fluency_ss=as.numeric(as.character(task_data_typ$gort_fluency_ss))

corstars(task_data,method="pearson")#you need to run the function first
corstars(task_data_dys,method="pearson")#you need to run the function first
corstars(task_data_typ,method="pearson")#you need to run the function first

#source("~/Dropbox (MIT)/how-to/stats/R-related/a.pcor.test.R")
#a.pcor.test(task_data$aud_acc,task_data$WR,task_data[,c("IQ","Age")],method="p")
#    estimate     p.value statistic  n gn  Method            Use
# 1 0.5122314 0.000505773   3.47768 38  2 Pearson Var-Cov matrix
#a.pcor.test(task_data_dys$aud_slope_scale,task_data_dys$WA,task_data_dys[,c("IQ","Age")],method="p")
#     estimate   p.value statistic  n gn  Method            Use
# 1 -0.3995094 0.1483509 -1.445381 15  2 Pearson Var-Cov matrix
#cor.test(task_data_dys$aud_slope_scale,task_data_dys$WA,method="p")
#     estimate   p.value statistic  n gn  Method            Use
# 1 -0.3995094 0.1383509 -1.445381 15  2 Pearson Var-Cov matrix

library(mediation)
m0 = lm(WA~aud_slope_scale,data=task_data_dys)
m1 = lm(PA~aud_slope_scale,data=task_data_dys)
m2 = lm(WA~aud_slope_scale + PA, data = task_data_dys)
results = mediate(m1, m2, treat = 'aud_slope_scale',mediator='PA',boot = TRUE, sims = 1000)
summary(results)

BayesFactor::correlationBF(task_data$aud_acc, task_data$WR)

ggplot(d_all, aes(x = aud_acc, y = WR)) +
  stat_smooth (
    method = "glm",
    formula = y ~ x,
    colour = "black",
    size = 1) +
  geom_point(aes(size = 3,shape = Subgroup)) +
  labs(x = "ASL Accuracy ", y = "Decoding Skills") +
  theme(axis.title = element_text(family = "Trebuchet MS", size = 20))+ theme(panel.background = element_blank(),legend.position = "none") + theme(axis.text = element_text(size = 20))

ggplot(d_all_dys, aes(x = aud_acc, y = WR)) +
  stat_smooth (
    method = "glm",
    formula = y ~ x,
    colour = "black",
    size = 1) +
  geom_point(aes(size = 3)) +
  labs(x = "ASL Accuracy", y = "Decoding Skills") +
  theme(axis.title = element_text(family = "Trebuchet MS", size = 20))+ theme(panel.background = element_blank(),legend.position = "none") + theme(axis.text = element_text(size = 20))


ggplot(d_all_dys, aes(x = aud_slope_scale, y = WA)) +
  stat_smooth (
    method = "glm",
    formula = y ~ x,
    colour = "black",
    size = 1) +
  geom_point(aes(size = 3)) +
  labs(x = "ASL RT Slope", y = "Nonword Decoding") +
  theme(axis.title = element_text(family = "Trebuchet MS", size = 20))+ theme(panel.background = element_blank(),legend.position = "none") + theme(axis.text = element_text(size = 20))

ggplot(d_all_dys, aes(x = vis_slope_scale, y = PA)) +
  stat_smooth (
    method = "glm",
    formula = y ~ x,
    colour = "black",
    size = 1) +
  geom_point(aes(size = 3)) +
  labs(x = "VSL RT Slope ", y = "Phonological Awareness") +
  theme(axis.title = element_text(family = "Trebuchet MS", size = 20))+ theme(panel.background = element_blank(),legend.position = "none") + theme(axis.text = element_text(size = 20))
```

```{r}
#mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale
BayesFactor::correlationBF(task_data$vis_slope_scale, task_data$aud_slope_scale)
BayesFactor::correlationBF(task_data$mean_rp, task_data$WR)
BayesFactor::correlationBF(task_data$mean_mt_t, task_data$WR)
BayesFactor::correlationBF(task_data$mean_mt_e, task_data$WR)
BayesFactor::correlationBF(task_data$aud_acc, task_data$WR)
BayesFactor::correlationBF(task_data$vis_acc, task_data$WR)
BayesFactor::correlationBF(task_data$aud_slope_scale, task_data$WR)
BayesFactor::correlationBF(task_data$vis_slope_scale, task_data$WR)

BayesFactor::correlationBF(task_data$mean_rp, task_data$PA)
BayesFactor::correlationBF(task_data$mean_mt_t, task_data$PA)
BayesFactor::correlationBF(task_data$mean_mt_e, task_data$PA)
BayesFactor::correlationBF(task_data$aud_acc, task_data$PA)
BayesFactor::correlationBF(task_data$vis_acc, task_data$PA)
BayesFactor::correlationBF(task_data$aud_slope_scale, task_data$PA)
BayesFactor::correlationBF(task_data$vis_slope_scale, task_data$PA)

BayesFactor::correlationBF(task_data_typ$mean_rp, task_data_typ$WR)
BayesFactor::correlationBF(task_data_typ$mean_mt_t, task_data_typ$WR)
BayesFactor::correlationBF(task_data_typ$mean_mt_e, task_data_typ$WR)
BayesFactor::correlationBF(task_data_typ$aud_acc, task_data_typ$WR)
BayesFactor::correlationBF(task_data_typ$vis_acc, task_data_typ$WR)
BayesFactor::correlationBF(task_data_typ$aud_slope_scale, task_data_typ$WR)
BayesFactor::correlationBF(task_data_typ$vis_slope_scale, task_data_typ$WR)

BayesFactor::correlationBF(task_data_typ$mean_rp, task_data_typ$PA)
BayesFactor::correlationBF(task_data_typ$mean_mt_t, task_data_typ$PA)
BayesFactor::correlationBF(task_data_typ$mean_mt_e, task_data_typ$PA)
BayesFactor::correlationBF(task_data_typ$aud_acc, task_data_typ$PA)
BayesFactor::correlationBF(task_data_typ$vis_acc, task_data_typ$PA)
BayesFactor::correlationBF(task_data_typ$aud_slope_scale, task_data_typ$PA)
BayesFactor::correlationBF(task_data_typ$vis_slope_scale, task_data_typ$PA)

BayesFactor::correlationBF(task_data_dys$mean_rp, task_data_dys$WR)
BayesFactor::correlationBF(task_data_dys$mean_mt_t, task_data_dys$WR)
BayesFactor::correlationBF(task_data_dys$mean_mt_e, task_data_dys$WR)
BayesFactor::correlationBF(task_data_dys$aud_acc, task_data_dys$WR)
BayesFactor::correlationBF(task_data_dys$vis_acc, task_data_dys$WR)
BayesFactor::correlationBF(task_data_dys$aud_slope_scale, task_data_dys$WR)
BayesFactor::correlationBF(task_data_dys$vis_slope_scale, task_data_dys$WR)

BayesFactor::correlationBF(task_data_dys$mean_rp, task_data_dys$PA)
BayesFactor::correlationBF(task_data_dys$mean_mt_t, task_data_dys$PA)
BayesFactor::correlationBF(task_data_dys$mean_mt_e, task_data_dys$PA)
BayesFactor::correlationBF(task_data_dys$aud_acc, task_data_dys$PA)
BayesFactor::correlationBF(task_data_dys$vis_acc, task_data_dys$PA)
BayesFactor::correlationBF(task_data_dys$aud_slope_scale, task_data_dys$PA)
BayesFactor::correlationBF(task_data_dys$vis_slope_scale, task_data_dys$PA)

BayesFactor::correlationBF(task_data$mean_rp, task_data$mean_mt_t)
BayesFactor::correlationBF(task_data$mean_rp, task_data$mean_mt_e)
BayesFactor::correlationBF(task_data$mean_rp, task_data$aud_acc)
BayesFactor::correlationBF(task_data$mean_rp, task_data$vis_acc)
BayesFactor::correlationBF(task_data$mean_rp, task_data$aud_slope_scale)
BayesFactor::correlationBF(task_data$mean_rp, task_data$vis_slope_scale)

BayesFactor::correlationBF(task_data$mean_mt_t, task_data$mean_mt_e)
BayesFactor::correlationBF(task_data$mean_mt_t, task_data$aud_acc)
BayesFactor::correlationBF(task_data$mean_mt_t, task_data$vis_acc)
BayesFactor::correlationBF(task_data$mean_mt_t, task_data$aud_slope_scale)
BayesFactor::correlationBF(task_data$mean_mt_t, task_data$vis_slope_scale)


BayesFactor::correlationBF(task_data$mean_mt_e, task_data$aud_acc)
BayesFactor::correlationBF(task_data$mean_mt_e, task_data$vis_acc)
BayesFactor::correlationBF(task_data$mean_mt_e, task_data$aud_slope_scale)
BayesFactor::correlationBF(task_data$mean_mt_e, task_data$vis_slope_scale)


BayesFactor::correlationBF(task_data$aud_acc, task_data$vis_acc)
BayesFactor::correlationBF(task_data$aud_acc, task_data$aud_slope_scale)
BayesFactor::correlationBF(task_data$aud_acc, task_data$vis_slope_scale)

BayesFactor::correlationBF(task_data$vis_acc, task_data$aud_slope_scale)
BayesFactor::correlationBF(task_data$vis_acc, task_data$vis_slope_scale)


BayesFactor::correlationBF(task_data$aud_slope_scale, task_data$vis_slope_scale)
```
###Everyone

```{r, echo=FALSE, include=TRUE}
#corstars(task_data,method="pearson")#you need to run the function first

library(corrr)
x <- correlate(task_data)
x %>% 
  focus(slope_me,slope_mt, slopeProp_On, vis_slope_scale,aud_slope_scale,aud_fam_rt,vis_fam_rt)%>% fashion()

```
```{r, echo=FALSE, include=TRUE}
task_only<-d_all%>%ungroup%>%dplyr::select(slopeProp_On,slope_mt,slope_me,vis_slope_scale,aud_slope_scale,aud_fam_rt,vis_fam_rt)
cor<-round(cor(task_only,use="complete.obs"),2)
cor
upper<-cor
upper[upper.tri(cor)]<-""
upper<-as.data.frame(upper)
source('correlation_matrix_function.R')
correlation_matrix(task_only)
save_correlation_matrix(task_only,
                        filename = "task_correlations.csv",
                        digits=3,
                        use='lower')
```

### Dys only

- both the rotary pursuit and ASL accuracy/RT are related to reading
- RP performance is associated with better reading

```{r, echo=FALSE, include=TRUE}
#corstars(task_data_dys,method="pearson")#you need to run the function first
x_d <- correlate(task_data_dys)
x_d %>% 
   focus(slope_me,slope_mt, slopeProp_On, vis_slope_scale,vis_fam_rt,aud_slope_scale,aud_fam_rt)%>% fashion()
plot(task_data_dys$slopeProp_On,task_data_dys$WR)
plot(task_data_typ$slopeProp_On,task_data_typ$WR)

```

```{r, echo=FALSE}

ggplot(task_data_dys, aes(x = WA, y = slopeProp_On)) +
  stat_smooth (
    method = "glm",
    formula = y ~ x,
    colour = "black",
    size = 1) +
  geom_point(aes(size = 3)) +
  labs(x = "Word Attack ", y = "Rotary Pursuit") +
  theme(axis.title = element_text(family = "Trebuchet MS", size = 14))+ theme(panel.background = element_blank(),legend.position = "none")
```
```{r, echo=FALSE}

ggplot(task_data_dys, aes(x = RAN_2Set, y = aud_slope_scale)) +
  stat_smooth (
    method = "glm",
    formula = y ~ x,
    colour = "black",
    size = 1) +
  geom_point(aes(size = 3)) +
  labs(x = "RAN 2Set ", y = "ASL Slope") +
  theme(axis.title = element_text(family = "Trebuchet MS", size = 14))+ theme(panel.background = element_blank(),legend.position = "none")
```

### Typ only

- better VSL is related to worse reading

```{r, echo=FALSE, include=TRUE}
#corstars(task_data_typ,method="pearson")#you need to run the function first
x_t <- correlate(task_data_typ)
x_t %>% 
  focus(slope_me,slope_mt, slopeProp_On, vis_slope_scale,vis_fam_rt,aud_slope_scale,aud_fam_rt)%>% fashion()

```
