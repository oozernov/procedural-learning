#ggsave("mt_t011222.png",width=6, height=4)
```
```{r, echo=FALSE,warning = FALSE}
mt_e<-ggplot(data = mtEPlot, aes(x=trial, y=meanE, color = Subgroup))+
geom_line(size=1.5) +geom_point(size=2)  +
scale_color_manual(values=c('#00BDD0','#E7861B'))+
geom_errorbar(aes(ymin=meanE-se,ymax=meanE+se),
width=.2,  size=0.5)+
scale_x_continuous(breaks=seq(0,10,1))+
#scale_y_continuous(limits = c(0.2, 0.5))+
theme(
axis.title = element_text(family = "Times New Roman", size = 20),
legend.key.size = unit(1, "cm"),
axis.text.x = element_text(size = 15),
axis.text.y = element_text(size = 15))  +
labs(x = "Trials", y = "Number of Errors") +
theme(panel.background = element_rect(fill = "white", colour = "grey50"),text=element_text(size=16,family="Times New Roman"),legend.key.size = unit(0.8, "cm"),
legend.text = element_text(
size = 16,
face = 'bold'
),
legend.title = element_blank(),)+
theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))
mt_e2<-mt_e + theme(legend.position = "none")
#ggsave("mt_e011222.png",width=6, height=4)
```
\newpage
# Statistical Learning
```{r, echo=FALSE,warning = FALSE}
names(SL)[names(SL) == "subj"] <- "PartID"
d_all<-merge(d,mt_df,all = TRUE)
d_all <-merge(d_all,rp_df,all=TRUE)
d_all <-merge(d_all,SL,all=TRUE)
table(SL$group)
```
```{r,echo=FALSE,warning = FALSE, include=FALSE}
subj_table_vsl<-read.csv("sl_analysis/vsl_rt_subj_table.csv")
fam_trial_vsl<-read.csv("sl_analysis/vsl_rt_trial.csv")
fam_trial_vsl_scale<-read.csv("sl_analysis/vsl_rt_scale_trial.csv")
subj_table_tsl<-read.csv("sl_analysis/tsl_rt_subj_table.csv")
fam_trial_tsl<-read.csv("sl_analysis/tsl_rt_trial.csv")
fam_trial_tsl_scale<-read.csv("sl_analysis/tsl_rt_scale_trial.csv")
#need to rename from Subj  to PartID
names(subj_table_vsl)[names(subj_table_vsl)=="subj"] <- "PartID"
names(fam_trial_vsl)[names(fam_trial_vsl)=="subj"] <- "PartID"
names(fam_trial_vsl_scale)[names(fam_trial_vsl_scale)=="subj"] <- "PartID"
names(subj_table_tsl)[names(subj_table_tsl)=="subj"] <- "PartID"
names(fam_trial_tsl)[names(fam_trial_tsl)=="subj"] <- "PartID"
names(fam_trial_tsl_scale)[names(fam_trial_tsl_scale)=="subj"] <- "PartID"
```
```{r, echo=FALSE,warning = FALSE,include=FALSE}
data<-as_tibble(subj_table_tsl)
data %>%
group_by(Subgroup) %>%
dplyr::summarise(
count = n(),
rt = qwraps2::mean_sd(mean_rt),
slope = qwraps2::mean_sd(rt_slope),
d_prime = qwraps2::mean_sd(dprime),
hits = qwraps2::mean_sd(hit_rate)
)
```
- remove outliers who have hit rate lower than and equal to 0.25 (remaining participant: 14 DD and 18 TYP)
- participants removed from analysis: ABCD_1705 ABCD_1720 ABCD_1747 ABCD_1767 ABCD_1783 ABCD_1788 ABCD_1709 ABCD_1724
```{r,echo=FALSE,warning=FALSE,include=FALSE}
usable_tsl_rt<-subj_table_tsl[subj_table_tsl$hit_rate>0.25,]$PartID
subj_table_tsl_usable <-subset(subj_table_tsl,PartID %in% usable_tsl_rt)
data<-as_tibble(subj_table_tsl_usable)
data %>%
group_by(Subgroup) %>%
dplyr::summarise(
count = n(),
rt = qwraps2::mean_sd(mean_rt),
slope = qwraps2::mean_sd(rt_slope),
d_prime = qwraps2::mean_sd(dprime),
hits = qwraps2::mean_sd(hit_rate)
)
```
# ASL Analysis
### RT by Trial Analysis
- There is no significant group difference in baseline speed for TSL.
```{r,echo=FALSE,warning = FALSE}
t.test(subj_table_tsl_usable$mean_rt~subj_table_tsl_usable$Subgroup)
cohen.d(mean_rt~Subgroup,data=subj_table_tsl_usable)
```
- There is no significant group difference in detection accuracy for TSL
```{r,echo=FALSE,warning = FALSE}
t.test(hit_rate~Subgroup,data=subj_table_tsl_usable)
cohen.d(hit_rate~Subgroup,data=subj_table_tsl_usable)
```
- No RT effect of group or interaction tested either by lm or lmer
```{r,echo=FALSE,warning=FALSE}
fam_trial_tsl_usable <-subset(fam_trial_tsl,PartID %in% usable_tsl_rt)
fam_trial_tsl_usable_s <-subset(fam_trial_tsl_scale,PartID %in% usable_tsl_rt)
fam_tsl_age_gender_iq = merge(fam_trial_tsl_usable,d[,c(1,3,4,6)],all.x=TRUE)
fam_tsl_s_age_gender_iq = merge(fam_trial_tsl_usable_s,d[,c(1,3,4,6)],all.x=TRUE)
model2_cov <- lmer(rt_col~Age+Sex+kbit_ss+reindex*Subgroup+(1+reindex|PartID),data=fam_tsl_age_gender_iq)
summary(model2_cov)
r2beta(model2_cov, method = "nsj")
```
- ANCOVA with covariates (RT slope data) - no group effect
```{r,echo=FALSE,warning = FALSE}
subj_table_tsl_gender_iq = merge(subj_table_tsl_usable,d[,c(1,3,4,6)],all.x=TRUE)
tsl_rt_ancova=lm(rt_slope~Subgroup+Age+Sex+kbit_ss,data=subj_table_tsl_gender_iq)
summary(tsl_rt_ancova)
```
#### Plot of ASL RT
- RT as the function of Target repetition
```{r,echo=FALSE}
tsl_rt_plot<-dplyr::summarise(group_by(fam_trial_tsl,Subgroup,reindex), n = n(),
mean=mean(rt_col,na.rm = T), sd=sd(rt_col,na.rm = T),se = sd/sqrt(n))
tsl_rt<-ggplot(data = tsl_rt_plot, aes(x=reindex, y=mean, col=Subgroup))+
geom_line(size=1.5) +geom_point(size=2)  +
scale_color_manual(values=c('#00BDD0','#E7861B'))+
geom_errorbar(aes(ymin=mean-se,ymax=mean+se),
width=.2,  size=0.5)+
scale_x_continuous(breaks=seq(4,48,4))+
#scale_y_continuous(limits = c(0.2, 0.5))+
theme(
axis.title = element_text(family = "Trebuchet MS", size = 20),
legend.key.size = unit(1, "cm"),
axis.text.x = element_text(size = 15),
axis.text.y = element_text(size = 15))  +
labs(x = "Trials", y = "Response Time (ms)") +
theme(panel.background = element_rect(fill = "white", colour = "grey50")) +
theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))
tsl_rt2<-tsl_rt + theme(legend.position = "none")
#ggsave("tsl_rt011222.png",width=7, height=4)
```
### Plot ASL RT Slope
```{r,echo=FALSE}
asl_slope<-subj_table_tsl_usable%>%dplyr::select("PartID","Subgroup","rt_slope")
asl_slope<-na.omit(asl_slope)
asl_slope2 = asl_slope %>%
dplyr::group_by(PartID, Subgroup) %>%
dplyr::summarise(mean = mean(rt_slope, na.rm = T))
multi.group_asl <-
asl_slope2 %>%
dabestr::dabest(Subgroup,mean,
idx = list(c("TYP","DD")),
paired = FALSE
)
multi.group_asl_2 <- dabestr::cohens_d(multi.group_asl)
plot(multi.group_asl_2, palette=c("blue","red"),rawplot.ylabel = "ASL Time Slope")
```
####VSL Slope Analysis
```{r,echo=FALSE,warning=FALSE}
data<-as_tibble(subj_table_vsl)
data %>%
group_by(Subgroup) %>%
dplyr::summarise(
count = n(),
rt = qwraps2::mean_sd(mean_rt),
slope = qwraps2::mean_sd(rt_slope),
d_prime = qwraps2::mean_sd(dprime),
hits = qwraps2::mean_sd(hit_rate)
)
```
- There is no significant group difference in baseline speed for VSL.
```{r,echo=FALSE,warning = FALSE}
t.test(subj_table_vsl$mean_rt~subj_table_vsl$Subgroup)
t.test(subj_table_vsl$hit_rate~subj_table_vsl$Subgroup)
cohen.d(mean_rt~Subgroup,data=subj_table_vsl)
cohen.d(hit_rate~Subgroup,data=subj_table_vsl)
```
- There is no significant group difference in target detection accuracy for VSL
```{r,echo=FALSE,warning = FALSE}
subj_table_vsl_iq_age = merge(data,d[,c(1,3,4,6)],all.x=TRUE)
summary(lm(dprime~Age+Sex+kbit_ss+Subgroup,data=subj_table_vsl_iq_age))
```
- The DD group had a faster RT acceleration than the TYP group (significant group x trial index interaction tested by lm and marginal interaction tested by lmer)
```{r,echo=FALSE,warning=FALSE}
fam_vsl_age_gender_iq = merge(fam_trial_vsl,d[,c(1,3,4,6)],all.x=TRUE)
fam_vsl_s_age_gender_iq = merge(fam_trial_vsl_scale,d[,c(1,3,4,6)],all.x=TRUE)
model2_cov <- lmer(rt_col~Age+Sex+kbit_ss+reindex*Subgroup+(1+reindex|PartID),data=fam_vsl_age_gender_iq)
summary(model2_cov)
r2beta(model2_cov, method = "nsj")
```
- ANCOVA with covariates (from the slope data): marginal group effect.
```{r,echo=FALSE,warning = FALSE}
subj_table_vsl_gender_iq = merge(subj_table_vsl,d[,c(1,3,4,6)],all.x=TRUE)
vsl_rt_ancova=aov(rt_slope~Subgroup+Age+Sex+kbit_ss,data=subj_table_vsl_gender_iq)
summary(vsl_rt_ancova)
```
- within DYS group
```{r,echo=FALSE,warning = FALSE}
model2_DYS <- lmer(rt_col~Age+Sex+kbit_ss+reindex+(1+reindex|PartID),data=fam_vsl_age_gender_iq[fam_vsl_age_gender_iq$Subgroup=="DD",])
summary(model2_DYS)
```
- within TYP group
```{r,echo=FALSE,warning = FALSE}
model2_TYP <- lmer(rt_col~Age+Sex+kbit_ss+reindex+(1+reindex|PartID),data=fam_vsl_age_gender_iq[fam_vsl_age_gender_iq$Subgroup=="TYP",])
summary(model2_TYP)
```
####Plot of VSL RT
- RT as the function of Target repetition
```{r,echo=FALSE}
vsl_rt_plot<-dplyr::summarise(group_by(fam_trial_vsl,Subgroup,reindex), n = n(),
mean=mean(rt_col,na.rm = T), sd=sd(rt_col,na.rm = T),se = sd/sqrt(n))
vsl_rt<-ggplot(data = vsl_rt_plot, aes(x=reindex, y=mean, color = Subgroup))+
geom_line(size=1.5) +geom_point(size=2)  +
scale_color_manual(values=c('#00BDD0','#E7861B'))+
geom_errorbar(aes(ymin=mean-se,ymax=mean+se),
width=.2,  size=0.5)+
scale_x_continuous(breaks=seq(2,24,2))+
#scale_y_continuous(limits = c(0.2, 0.5))+
theme(
axis.title = element_text(family = "Trebuchet MS", size = 20),
legend.key.size = unit(1, "cm"),
axis.text.x = element_text(size = 15),
axis.text.y = element_text(size = 15))  +
labs(x = "Trials", y = "Response Time (ms)") +
theme(panel.background = element_rect(fill = "white", colour = "grey50")) +
theme(axis.line = element_line(arrow = arrow(angle = 15, length = unit(.15,"inches"),type = "closed")))
vsl_rt2<-vsl_rt + theme(legend.position = "none")
ggsave("vsl_rt011222.png",width=7, height=4)
```
#### plot mean RT slope across the two groups
```{r, echo=FALSE,warning = FALSE}
vsl_slope<-subj_table_vsl%>%dplyr::select("PartID","Subgroup","rt_slope")
vsl_slope<-na.omit(vsl_slope)
vsl_slope2 = vsl_slope %>%
dplyr::group_by(PartID, Subgroup) %>%
dplyr::summarise(mean = mean(rt_slope, na.rm = T))
multi.group_vsl <-
vsl_slope2 %>%
dabestr::dabest(Subgroup,mean,
idx = list(c("TYP","DD")),
paired = FALSE
)
multi.group_vsl_2 <- dabestr::cohens_d(multi.group_vsl)
plot(multi.group_vsl_2, palette=c("blue","red"),rawplot.ylabel = "VSL Slope")
```
#### Combine slope data of both tasks
```{r,echo=FALSE,warning=FALSE,include=FALSE}
colnames(subj_table_tsl_usable)[1]="subj"
colnames(subj_table_vsl)[1]="subj"
subj_table_tsl_usable$task = "Auditory"
subj_table_vsl$task = "Visual"
all_subj_slope = rbind(subj_table_vsl,subj_table_tsl_usable)
fam_trial_vsl_scale$task="Visual"
fam_trial_tsl_usable_s$task="Auditory"
all_fam_trials = rbind(fam_trial_vsl_scale,fam_trial_tsl_usable_s)
```
#### Using scaled RT, check interactions between task and group.
- both lm and lmer models: task x trial interaction: visual task show faster acceleration across the two groups; task x trial x group interaction (marginal): group difference in slope is greater in VSL than ASL
```{r,echo=FALSE,warning=FALSE}
all_subj_slope$tasknum=""
for (id in all_subj_slope$subj) {
all_subj_slope[all_subj_slope$subj==id,]$tasknum = nrow(all_subj_slope[all_subj_slope$subj==id,])
}
all_subj_slope_complete = subset(all_subj_slope,tasknum==2)
all_subj_slope_age_gender_iq = merge(all_subj_slope_complete,d[,c(1,3,4,6)],all.x=TRUE)
all_fam_trials_age_gender_iq = merge(all_fam_trials,d[,c(1,3,4,6)],all.x=TRUE)
model_rt_lmer_cov <- lmer(rt_col~Age+Sex+kbit_ss+task*reindex*Subgroup+(1+task|PartID)+(task|reindex),data=all_fam_trials_age_gender_iq)
print(summary(model_rt_lmer_cov))
```
- ANCOVA for interaction between task and group (no significant interaction)
```{r,echo=FALSE,warning = FALSE}
all_sl_slope_ancova = lm(rt_slope_scale~Subgroup*task+Age+Sex+kbit_ss,data=all_subj_slope_age_gender_iq)
print(summary(all_sl_slope_ancova))
```
## SL Accuracy Analysis
#### Accuracy Data Summary (mean +/- sd)
```{r,echo=FALSE,warning=FALSE}
all_accuracy=read.csv("sl_analysis/all_sl_accuracy.csv")
all_acc_table=read.csv("sl_analysis/sl_acc_subj_table.csv")
vsl_acc_table=subset(all_acc_table,task=="Visual")
tsl_acc_table=subset(all_acc_table,task=="Auditory")
vsl_accuracy=subset(all_accuracy,task=="Visual")
tsl_accuracy=subset(all_accuracy,task=="Auditory")
data<-as_tibble(all_acc_table)
data %>%
group_by(Subgroup,task) %>%
dplyr::summarise(
count = n(),
accuracy = qwraps2::mean_sd(subj_corr)
)
```
#### ASL and VSL Accuracy
- both groups performed above chance for both tasks
```{r,echo=FALSE,warning=FALSE}
DD_acc_vsl = subset(vsl_acc_table,Subgroup=="DD")
TYP_acc_vsl = subset(vsl_acc_table,Subgroup=="TYP")
DD_acc_tsl = subset(tsl_acc_table,Subgroup=="DD")
TYP_acc_tsl = subset(tsl_acc_table,Subgroup=="TYP")
t.test(DD_acc_vsl$subj_corr,mu=0.5,alternative = "greater")
t.test(DD_acc_tsl$subj_corr,mu=0.5,alternative = "greater")
t.test(TYP_acc_vsl$subj_corr,mu=0.5,alternative = "greater")
t.test(TYP_acc_tsl$subj_corr,mu=0.5,alternative = "greater")
```
```{r,echo=FALSE}
vsl_accuracy = subset(all_accuracy,task=="Visual")
tsl_accuracy = subset(all_accuracy,task=="Auditory")
vsl_accuracy_age_gender_iq = merge(vsl_accuracy,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
tsl_accuracy_age_gender_iq = merge(tsl_accuracy,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
```
- generalized linear effect modeling within each task (both models failed to converge with IQ included, removing IQ from the covariates fix the issues)
-  VSL, no group effect
```{r,echo=FALSE}
model_vslacc_lmer_cov <- glmmPQL(corr~Age+Sex+kbit_ss+Subgroup,random=~1|PartID/trial,data=vsl_accuracy_age_gender_iq,family="binomial")
print(summary(model_vslacc_lmer_cov))
r2beta(model_vslacc_lmer_cov,method="sgv")
```
```{r,echo=FALSE, include=FALSE}
all_acc_table_age_gender_iq = merge(all_acc_table,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
vsl_acc_table = subset(all_acc_table_age_gender_iq,task == "Visual")
asl_acc_table = subset(all_acc_table_age_gender_iq,task == "Auditory")
#vslacc_ancova <- aov(subj_corr~Age+Sex+IQ+Subgroup,data=vsl_acc_table)
#print(summary(vslacc_ancova))
```
- Significant group effects for ASL (Typ>Dys)
```{r,echo=FALSE}
model_tslacc_lmer_cov <- glmmPQL(corr~Age+Sex+kbit_ss+Subgroup,random=~1|PartID/trial,data=tsl_accuracy_age_gender_iq,family="binomial")
print(summary(model_tslacc_lmer_cov))
r2beta(model_tslacc_lmer_cov,method="sgv")
```
```{r,echo=FALSE, include=FALSE}
#aslacc_ancova <- aov(subj_corr~Age+Sex+IQ+Subgroup,data=asl_acc_table)
#print(summary(aslacc_ancova))
```
#### Plot VSL Accuracy
```{r,echo=FALSE}
vsl_acc_summary = vsl_acc_table %>%
dplyr::group_by(PartID, Subgroup) %>%
dplyr::summarise(mean = mean(subj_corr, na.rm = T))
multi.group_vsl_acc <-
vsl_acc_summary %>%
dabestr::dabest(Subgroup,mean,
idx = list(c("TYP","DD")),
paired = FALSE
)
multi.group_vsl_acc_2 <- dabestr::cohens_d(multi.group_vsl_acc)
plot(multi.group_vsl_acc_2, palette=c("blue","red"),rawplot.ylabel = "VSL Accuracy")
```
#### Plot ASL Accuracy
```{r,echo=FALSE}
tsl_acc_summary = tsl_acc_table %>%
dplyr::group_by(PartID, Subgroup) %>%
dplyr::summarise(mean = mean(subj_corr, na.rm = T))
multi.group_tsl_acc <-
tsl_acc_summary %>%
dabestr::dabest(Subgroup,mean,
idx = list(c("TYP","DD")),
paired = FALSE
)
multi.group_tsl_acc_2 <- dabestr::cohens_d(multi.group_tsl_acc)
plot(multi.group_tsl_acc_2, palette=c("blue","red"),rawplot.ylabel = "ASL Accuracy")
```
#### Task by Group Interaction
- LME: main effect of task (visual > auditory); main effect of group (TYP > DD); interaction between group and task
```{r,echo=FALSE}
all_accuracy_age_gender_iq = merge(all_accuracy,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
model_acc_lmer <- glmmPQL(corr~task*Subgroup+Age+Sex,random = ~1|PartID/trial/task,data=all_accuracy_age_gender_iq,family="binomial")
print(summary(model_acc_lmer))
r2beta(model_acc_lmer,method="sgv")
```
- ANCOVA: marginal effect of task (Visual > Auditory)
```{r,echo=FALSE,warning=FALSE}
all_acc_table_complete = subset(all_acc_table,PartID="ABCD_1708")
all_acc_table_complete = subset(all_acc_table_complete,PartID!="ABCD_1727")
all_acc_table_age_gender_iq = merge(all_acc_table_complete,d[,c(1,3,4,6)],by="PartID",all.x=TRUE)
model_acc <- lm(subj_corr~task*Subgroup+Age+Sex+kbit_ss,data=all_acc_table_age_gender_iq)
print(summary(model_acc))
```
#### Plot  accuracy by group and task
```{r,echo=FALSE}
stat.test <- all_acc_table %>%
group_by(task) %>%
tukey_hsd(subj_corr~Subgroup)
stat.test
stat.test <- stat.test %>% add_xy_position(x = "group", fun = "mean_se")
all_acc_table$Subgroup = as.factor(all_acc_table$Subgroup)
#cbbPalette <- c("#00BDD0","#E7861B")
ggplot() +
geom_bar(aes(x = Subgroup,y = subj_corr,fill = Subgroup),data=all_acc_table,colour = '#000000',fun.data = mean_sdl,fun.args = list(mult = 1),stat = 'summary',position = position_dodge(width = 0.9)) +
scale_fill_manual("legend", values = c("DD" = "#00BDD0", "TYP" = "#E7861B"))+
theme_classic(base_size = 18.0) +
ylab(label = '% Correct') +
xlab(label = 'Group') +
#coord_cartesian(ylim = c(0.3,1)) +
geom_errorbar(aes(y = subj_corr, x = Subgroup),data=all_acc_table,size = 0.3,width = 0.2,fun.y = function(x) mean(x),fun.ymin = function(x) mean(x) - sd(x)/sqrt(length(x)),fun.ymax = function(x) mean(x) + sd(x)/sqrt(length(x)) ,stat = 'summary')+
geom_beeswarm(aes(x = Subgroup,y = subj_corr, colour = Subgroup),data=all_acc_table,dodge.width=1,cex=3.5) +
facet_wrap(task~.) +
scale_color_manual(values=c('black','black'))
```
#### VSL reliability
```{r,include=FALSE,warning = FALSE}
d <- matrix(nrow=40,ncol=32)
for(i in seq(from=1,to=40,by=1)){d[i,] <- rbind(vsl_accuracy$corr[((i-1)*32+1):(i*32)])}
psych::alpha(d,check.keys = TRUE)$total$std.alpha
vsl_rt <- subset(fam_trial_vsl,select=c(4,3,6))
vsl_rt_w<- spread(vsl_rt, reindex, rt_col)
vsl_rt_w<-select(vsl_rt_w,-PartID)
psych::alpha(vsl_rt_w,check.keys = TRUE)$total$std.alpha
```
#### ASL reliability
```{r,include=FALSE,warning = FALSE}
d <- matrix(nrow=40,ncol=32)
for(i in seq(from=1,to=40,by=1)){d[i,] <- rbind(tsl_accuracy$corr[((i-1)*32+1):(i*32)])}
psych::alpha(d,check.keys = TRUE)$total$std.alpha
asl_rt <- subset(fam_trial_tsl_usable,select=c(4,3,6))
asl_rt_w<- spread(asl_rt, reindex, rt_col)
asl_rt_w<-select(asl_rt_w,-PartID)
psych::alpha(asl_rt_w,check.keys = TRUE)$total$std.alpha
```
# Cross-task correlations
```{r,include=FALSE,warning = FALSE}
d_all$PA<-rowMeans(d_all[,c('Elision','Blending')])
d_all$WR<-rowMeans(d_all[,c('WID','WA')])
d_all_dys = subset(d_all,Subgroup == "DD")
d_all_typ = subset(d_all,Subgroup == "TYP")
task_data<-d_all%>%ungroup%>%dplyr::select(IQ,WR,Vocabulary,PA,Nonword,DigitsSpan,mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)
task_data_dys<-d_all_dys%>%ungroup%>%dplyr::select(IQ,WR,Vocabulary,PA,Nonword,DigitsSpan,mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)
task_data_typ<-d_all_typ%>%ungroup%>%dplyr::select(IQ,WR,Vocabulary,PA,Nonword,DigitsSpan,mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)
corstars(task_data,method="pearson")#you need to run the function first
```
###Everyone
```{r, echo=FALSE, include=TRUE}
#corstars(task_data,method="pearson")#you need to run the function first
library(corrr)
x <- correlate(task_data)
x %>%
focus(slope_me,slope_mt, slopeProp_On, vis_slope_scale,aud_slope_scale,aud_fam_rt,vis_fam_rt)%>% fashion()
```
```{r, echo=FALSE, include=TRUE}
task_only<-d_all%>%ungroup%>%dplyr::select(mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)
cor<-round(cor(task_only,use="complete.obs"),2)
cor
upper<-cor
upper[upper.tri(cor)]<-""
upper<-as.data.frame(upper)
source('correlation_matrix_function.R')
correlation_matrix(task_only)
save_correlation_matrix(task_only,
filename = "task_correlations.csv",
digits=3,
use='lower')
```
```{r}
#mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale
BayesFactor::correlationBF(task_data$vis_slope_scale, task_data$aud_slope_scale)
```
### Dys only
- both the rotary pursuit and ASL accuracy/RT are related to reading
- RP performance is associated with better reading
```{r, echo=FALSE, include=TRUE}
#corstars(task_data_dys,method="pearson")#you need to run the function first
x_d <- correlate(task_data_dys)
x_d %>%
focus(mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)%>% fashion()
plot(task_data_dys$slopeProp_On,task_data_dys$WR)
plot(task_data_typ$slopeProp_On,task_data_typ$WR)
```
```{r, echo=FALSE}
ggplot(task_data_dys, aes(x = WA, y = slopeProp_On)) +
stat_smooth (
method = "glm",
formula = y ~ x,
colour = "black",
size = 1) +
geom_point(aes(size = 3)) +
labs(x = "Word Attack ", y = "Rotary Pursuit") +
theme(axis.title = element_text(family = "Trebuchet MS", size = 14))+ theme(panel.background = element_blank(),legend.position = "none")
```
```{r, echo=FALSE}
ggplot(task_data_dys, aes(x = RAN_2Set, y = aud_slope_scale)) +
stat_smooth (
method = "glm",
formula = y ~ x,
colour = "black",
size = 1) +
geom_point(aes(size = 3)) +
labs(x = "RAN 2Set ", y = "ASL Slope") +
theme(axis.title = element_text(family = "Trebuchet MS", size = 14))+ theme(panel.background = element_blank(),legend.position = "none")
```
### Typ only
- better VSL is related to worse reading
```{r, echo=FALSE, include=TRUE}
#corstars(task_data_typ,method="pearson")#you need to run the function first
x_t <- correlate(task_data_typ)
x_t %>%
focus(mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)%>% fashion()
```
ggplot(task_data_dys, aes(x = RAN_2Set, y = aud_slope_scale)) +
stat_smooth (
method = "glm",
formula = y ~ x,
colour = "black",
size = 1) +
geom_point(aes(size = 3)) +
labs(x = "RAN 2Set ", y = "ASL Slope") +
theme(axis.title = element_text(family = "Trebuchet MS", size = 14))+ theme(panel.background = element_blank(),legend.position = "none")
BayesFactor::correlationBF(task_data$vis_slope_scale, task_data$aud_slope_scale)
d_all$PA<-rowMeans(d_all[,c('Elision','Blending')])
d_all$WR<-rowMeans(d_all[,c('WID','WA')])
d_all_dys = subset(d_all,Subgroup == "DD")
d_all_typ = subset(d_all,Subgroup == "TYP")
task_data<-d_all%>%ungroup%>%dplyr::select(IQ,WR,Vocabulary,PA,Nonword,DigitsSpan,mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)
task_data_dys<-d_all_dys%>%ungroup%>%dplyr::select(IQ,WR,Vocabulary,PA,Nonword,DigitsSpan,mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)
task_data_typ<-d_all_typ%>%ungroup%>%dplyr::select(IQ,WR,Vocabulary,PA,Nonword,DigitsSpan,mean_rp,mean_mt_t,mean_mt_e,aud_acc,vis_acc,aud_slope_scale,vis_slope_scale)
corstars(task_data,method="pearson")#you need to run the function first
cor.test(d_all$ran_2set_ss,d_all$vis_slope_scale)
cor.test(d_all$ran_2set_ss,d_all$vis_acc
cor.test(d_all$ran_2set_ss,d_all$vis_acc)
cor.test(d_all$ran_2set_ss,d_all$vis_fam_dprime)
cor.test(d_all$ran_2set_ss,d_all$vis_fam_rt)
plot(d_all$ran_2set_ss,d_all$vis_slope_scale)
plot(d_all$ran_2set_ss,d_all$vis_slope_scale)
plot(d_all$ran_2set_ss,d_all$aud_slope_scale)
plot(d_all$ran_2set_raw,d_all$aud_slope_scale)
plot(d_all$ran_2set_raw,d_all$vis_slope_scale)
