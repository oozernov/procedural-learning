summary(d$towre_sight_raw_behav1)
summary(d$towre_sight_raw_behav2)
summary(d$towre_sight_std_behav1)
summary(as.numeric(d$towre_sight_std_behav1))
summary(as.numeric(d$towre_sight_std_behav2))
summary(as.numeric(d$towre_sight_raw_behav1))
summary(as.numeric(d$towre_sight_raw_behav2))
d$towre_sight_raw_behav2
summary(d$gort_s)
#####Add Packages##################################################################
#Load packages for use (make sure these have been installed first (one time only));
library(ggplot2) # nice graphs
library(reshape) # rename, cast
library(stringr) # str_replace
library(psych)   # describeBy
library(arsenal) # freqlist
library(lme4)    # lmer (linear mixed effects models)
library(dplyr)
library(gridExtra)
library(grid)
library(tidyr)
library(anchors)
library(car)
##### Step 2: Set working Directory and cut down data ##############################
#setwd("C:/Users/Carso/Dropbox (MIT)/Carrroll_Project/Data")
library(RCurl)
data <- postForm(
uri= 'https://gabcap.mit.edu/api/',
token = 'CCB700F480D0C431491C43A6E96E3D26',
content='record',
format= 'csv',
returnFormat='csv'
)
con <- textConnection(data)
df <- read.csv(con)
#filter into carroll, and then Carroll that has 3rd score finalized
d <- df %>%dplyr::filter(df$eligible==0)
mean(d$childs_age)
summary(d$childs_age)
summary(df$childs_age)
View(df)
d <- df %>%dplyr::filter(df$eligible==0)
df$eligible
View(df)
beh=read.csv("~/Dropbox (MIT)/ABCD_Analysis/beh_group.csv")
scores=read.csv("~/Dropbox (MIT)/ABCD_Analysis/ABCDStudy_2019-04-19_2144.csv")
names(scores)[names(scores)=="ABCD.ID"] <- "ids"
music=read.csv("~/Dropbox (MIT)/ABCD_Analysis/ABCD_music_data.csv")
names(music)[names(music)=="ABCD.ID"] <- "ids"
library(dplyr)
d=merge(music,beh,'ids',all=FALSE)
d=merge(d, scores,'ids',all=FALSE)
d$music<-ifelse(d$music_y_n == 'Yes',1,0)
d$no_music<-ifelse(d$music_y_n == 'No',1,0)
beh=read.csv("~/Dropbox (MIT)/ABCD_Analysis/beh_group.csv")
scores=read.csv("~/Dropbox (MIT)/ABCD_Analysis/ABCDStudy_2019-04-19_2144.csv")
names(scores)[names(scores)=="ABCD.ID"] <- "ids"
music=read.csv("~/Dropbox (MIT)/ABCD_Analysis/ABCD_music_data.csv")
names(music)[names(music)=="ABCD.ID"] <- "ids"
library(dplyr)
d=merge(music,beh,'ids',all=FALSE)
d=merge(d, scores,'ids',all=FALSE)
d$music<-ifelse(d$music_y_n == 'Yes',1,0)
d$no_music<-ifelse(d$music_y_n == 'No',1,0)
counts <- d %>%
group_by(music_y_n) %>%
count(music_y_n)
counts
d$Subgroup.x
counts <- d %>%
group_by(music_y_n,Subgroup.x) %>%
count(music_y_n)
counts
counts <- d %>%
group_by(music_y_n,Subgroup.x) %>%
count(music_y_n,Subgroup.x)
counts
counts <- d %>%
group_by(music_y_n) %>%
count(Subgroup.x)
counts
test <- d %>%
group_by(music_y_n) %>%
summarize(total_years)
test <- d %>%
group_by(music_y_n) %>%
summarize(d$total_years)
tapply(d$total_years, d$Subgroup.x, summary)
tapply(d$total_years, d$music_y_n, summary)
tapply(d$KBIT.2.Matrices..Standard.Score, d$music_y_n, summary)
#####Add Packages##################################################################
#Load packages for use (make sure these have been installed first (one time only));
library(ggplot2) # nice graphs
library(reshape) # rename, cast
library(stringr) # str_replace
library(psych)   # describeBy
library(arsenal) # freqlist
library(lme4)    # lmer (linear mixed effects models)
library(dplyr)
library(gridExtra)
library(grid)
library(tidyr)
library(anchors)
library(car)
##### Step 2: Set working Directory and cut down data ##############################
#setwd("C:/Users/Carso/Dropbox (MIT)/Carrroll_Project/Data")
library(RCurl)
data <- postForm(
uri= 'https://gabcap.mit.edu/api/',
token = 'CCB700F480D0C431491C43A6E96E3D26',
content='record',
format= 'csv',
returnFormat='csv'
)
con <- textConnection(data)
df <- read.csv(con)
d <- df %>%dplyr::filter(df$eligible==0)
View(d)
d <- df %>%dplyr::filter(df$group___1==1 & df$eligible==0)
View(d)
names(d)[names(d)=="reader_id"] <- "ID"
d$WA_gain<-d$wrmt_wa_raw_behav2-d$wrmt_wa_raw_behav1
d$WID_gain<-d$wrmt_id_raw_behav2-d$wrmt_id_raw_behav1
d$WA_std_gain<-d$wrmt_wa_std_behav2-d$wrmt_wa_std_behav1
d$WID_gain_s<-d$wrmt_id_std_behav2-d$wrmt_id_std_behav1
d$gort_s<-d$gort_ori_std_behav2-d$gort_ori_std_behav1
ggplot(d2, aes(x = wrmt_wa_std_behav1, y = celf_usp_std_behav1)) +
geom_point(aes(), size = 4) + geom_smooth(method="lm", fill=NA, size=1.2)+
scale_shape_manual(values = c(1, 17)) +
labs(x = "Decoding", y = "Listening") +
theme(
axis.title = element_text(family = "Trebuchet MS", size = 20),
#legend.position ="none",
# legend.text = element_blank(),
legend.title = element_blank(),
panel.background = element_rect(fill = "transparent", colour = NA),
plot.background = element_rect(fill = "transparent", colour = NA),
axis.line = element_line(colour = "black"),
axis.text.x = element_text(size = 15),
axis.text.y = element_text(size = 15))
d2=d%>%dplyr::select(ID, pc,group___1,gender_behav_1,chron_age_behav_1,
doe_behav_1,doe_behav_2,morpho_raw_behav1,contains("std_behav1"),morpho_raw_behav2,contains("std_behav2"))
d <- df %>%dplyr::filter(df$group___1==1 & df$eligible==0)
#d <- d %>%filter(d$behavioral_2_database_complete==2)
names(d)[names(d)=="reader_id"] <- "ID"
d$WA_gain<-d$wrmt_wa_raw_behav2-d$wrmt_wa_raw_behav1
d$WID_gain<-d$wrmt_id_raw_behav2-d$wrmt_id_raw_behav1
d$WA_std_gain<-d$wrmt_wa_std_behav2-d$wrmt_wa_std_behav1
d$WID_gain_s<-d$wrmt_id_std_behav2-d$wrmt_id_std_behav1
d$gort_s<-d$gort_ori_std_behav2-d$gort_ori_std_behav1
d$pc=ifelse(d$wrmt_id_std_behav1 >= 90 & d$celf_usp_std_behav1<8,1,0 )
d$pc<-as.factor(d$pc)
d2=d%>%dplyr::select(ID, pc,group___1,gender_behav_1,chron_age_behav_1,
doe_behav_1,doe_behav_2,morpho_raw_behav1,contains("std_behav1"),morpho_raw_behav2,contains("std_behav2"))
d3=d%>%dplyr::select(ID, pc,group___1,gender_behav_1,chron_age_behav_1,
doe_behav_1,doe_behav_2,contains("raw_behav1"),contains("raw_behav2"))
d3$group___1<-as.factor(d3$group___1)
df$group___1
d_t <- df %>%dplyr::filter(df$group___1==2 & df$eligible==0)
d_t <- df %>%dplyr::filter(df$group___1==0 & df$eligible==0)
View(d_t)
d_t$wisc_digitbkwd_raw_behav1
#####Add Packages##################################################################
#Load packages for use (make sure these have been installed first (one time only));
library(ggplot2) # nice graphs
library(reshape) # rename, cast
library(stringr) # str_replace
library(psych)   # describeBy
library(arsenal) # freqlist
library(lme4)    # lmer (linear mixed effects models)
library(dplyr)
library(gridExtra)
library(grid)
library(tidyr)
library(anchors)
library(car)
##### Step 2: Set working Directory and cut down data ##############################
#setwd("C:/Users/Carso/Dropbox (MIT)/Carrroll_Project/Data")
#using API token to directly import the data from REDCAP (will always be up to date)
# input your own API token before running, I have it removed for data security reasons
library(RCurl)
data <- postForm(
uri= 'https://gabcap.mit.edu/api/',
token = 'AF727408A122B604E21A71694333A6B1',  #input token here
content='record',
format= 'csv',
returnFormat='csv'
)
con <- textConnection(data)
df <- read.csv(con)
# 2. Load packages for use (make sure these have been installed first (one time only));
library(ggplot2) # nice graphs
library(reshape) # rename, cast
library(stringr) # str_replace
library(psych)   # describeBy
library(arsenal) # freqlist
library(lme4)    # lmer (linear mixed effects models)
library(dplyr)
library(tidyr)
#filter into active participants and groups,
d <- df %>%filter(df$eligibility_complete==2)
names(d)[names(d)=="reader_id"] <- "ID"
carroll <- d %>%filter(d$group___1==1)
community <- d %>%filter(d$group___2==1)
names(d)[names(d)=="reader_id"] <- "ID"
#Reading
WID <- subset(d3, select=c(ID, wrmt_id_raw_behav1, wrmt_id_raw_behav2))
WID_long <- tidyr::gather(WID, time, WID, wrmt_id_raw_behav1:wrmt_id_raw_behav2, factor_key=TRUE)
WA <- subset(d2, select=c(ID, wrmt_wa_raw_behav1, wrmt_wa_raw_behav2))
WA_long <- gather(WA, time, WA, wrmt_wa_std_behav1:wrmt_wa_std_behav2, factor_key=TRUE)
library(foreign)
library(dplyr)
cusp = read.csv("read4ormore.csv",na.strings = c("", "NA","9999","7777","8888"))
read=read.csv("read_data.csv",na.strings = c("", "NA","9999","7777","8888"))
cusp2=read.csv("readoneormore4.csv",na.strings = c("", "NA","9999","7777","8888"))
d2<-merge(cusp,read2,'READ_ID')
no_inCusp<-subset(read,!(READ_ID %in% d2$READ_ID))
summary(as.integer(no_inCusp$W3WIraw))
summary(as.integer(d2$W3WIraw))
setwd("~/Dropbox/Other papers/Cusp Hypothesis")
setwd("~/Dropbox/Other papers/Cusp Hypothesis")
library(foreign)
library(dplyr)
cusp = read.csv("read4ormore.csv",na.strings = c("", "NA","9999","7777","8888"))
read=read.csv("read_data.csv",na.strings = c("", "NA","9999","7777","8888"))
cusp2=read.csv("readoneormore4.csv",na.strings = c("", "NA","9999","7777","8888"))
d2<-merge(cusp,read2,'READ_ID')
no_inCusp<-subset(read,!(READ_ID %in% d2$READ_ID))
summary(as.integer(no_inCusp$W3WIraw))
summary(as.integer(d2$W3WIraw))
install.packages("foreign")
d2<-merge(cusp,read2,'READ_ID')
d2<-merge(cusp,read,'READ_ID')
no_inCusp<-subset(read,!(READ_ID %in% d2$READ_ID))
summary(as.integer(no_inCusp$W3WIraw))
summary(as.integer(d2$W3WIraw))
View(cusp)
View(cusp2)
long=read.csv("long_data.csv",na.strings = c("", "NA","9999","7777","8888"))
d3<-merge(long,cusp,'READ_ID')
View(long)
View(cusp)
names(long)[names(long)=="READ"] <- "READ_ID"
d3<-merge(long,cusp,'READ_ID')
View(d3)
View(cusp)
names(cusp)
cusp_long<-long%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
names(long)
long=read.csv("ImagingKids_FinalData_T1_T4_Nov2016",na.strings = c("", "NA","9999","7777","8888"))
long=read.csv("ImagingKids_FinalData_T1_T4_Nov2016.csv",na.strings = c("", "NA","9999","7777","8888"))
names(long)[names(long)=="READ"] <- "READ_ID"
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
long=read.csv("ImagingKids_FinalData_T1_T4_Nov2016.csv",na.strings = c("", "NA","9999","7777","8888"))
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
names(long)[names(long)=="READ"] <- "READ_ID"
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
#cusp2=read.csv("readoneormore4.csv",na.strings = c("", "NA","9999","7777","8888"))
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
long=read.csv("ImagingKids_FinalData_T1_T4_Nov2016.csv",na.strings = c("", "NA","9999","7777","8888"))
names(long)[names(long)=="READ"] <- "READ_ID"
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0ss','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
long=read.csv("ImagingKids_FinalData_T1_T4_Nov2016.csv",na.strings = c("", "NA","9999","7777","8888"))
names(long)[names(long)=="READ"] <- "READ_ID"
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
long=read.csv("ImagingKids_FinalData_T1_T4_Nov2016.csv",na.strings = c("", "NA","9999","7777","8888"))
names(long)[names(long)=="READ"] <- "READ_ID"
cusp_long<-long%>%select('READ_ID','T1_KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
cusp_long<-long%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','
CTNRss0s','WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
cusp_long<-long%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
read=read.csv("all_data.csv",na.strings = c("", "NA","9999","7777","8888"))
long=read.csv("long_data.csv",na.strings = c("", "NA","9999","7777","8888"))
names(long)[names(long)=="READ"] <- "READ_ID"
names(read)[names(read)=="READ"] <- "READ_ID"
d_final<-merge(read,long_data)
d_final<-merge(read,long)
d_final<-merge(read,long,"READ_ID")
cusp_long<-d_final%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
names(d_final)
cusp_long<-d_final%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss.y','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS','W3WIss_T4')
cusp_long<-d_final%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss.y','RANOss.y','RANCss.y','RANCss.y',
'RANLss.y','CTOPP_Mean0sSS','W3WIss_T4')
View(cusp_long)
test<-na.omit(cusp_long)
View(test)
read$CTELss0s
View(read)
View(cusp_long)
View(cusp_long)
View(read)
View(d3)
View(long)
View(cusp_long)
setwd("~/Dropbox/Other papers/Cusp Hypothesis")
library(foreign)
library(dplyr)
read=read.csv("screening_data.csv",na.strings = c("", "NA","9999","7777","8888"))
cusp = read.csv("read4ormore.csv",na.strings = c("", "NA","9999","7777","8888"))
read2<-read%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss.y','RANOss.y','RANCss.y','RANCss.y',
'RANLss.y','CTOPP_Mean0sSS','W3WIss_T4')
read2<-read%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss','RANOss.y','RANCss.y','RANCss.y',
'RANLss.y','CTOPP_Mean0sSS')
read2<-read%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss.y','CTOPP_Mean0sSS')
read2<-read%>%select('READ_ID','KBITss','CTELss0s','CTBWss0s','CTNRss0s'
,'WRLIss','WRWIss','RANOss','RANCss','RANCss',
'RANLss','CTOPP_Mean0sSS')
long=read.csv("long_data_2.csv",na.strings = c("", "NA","9999","7777","8888"))
d_final<-merge(read2,long,"READ_ID")
View(d_final)
write.csv(d_final,"Cusp_data_long.csv")
View(long)
View(d_final)
---
title: "ABCD Analysis"
author: "Zhenghan Qi"
date: "June 16, 2020"
output:
pdf_document: default
html_document: default
---
```{r,echo=FALSE,warning=FALSE}
#Loading library
library(ggplot2)
library(knitr)
library(readr)
library(reshape)
library(reshape2)
library(lmerTest)
library(scales)
library(ggbeeswarm)
library(Hmisc)
#Initialize variables
total_participant <- 40 #40 vsl participants and 40 tsl participants
total_vsl_trial <- 24 #number of trials in the familiarization block
total_tsl_trial <- 48
length_vsl <- 533 #number of rows in a vsl excel file
length_tsl <- 832 #number of rows in a tsl excel file
total_test_trial <- 32
#Note: The code below is to work on the raw files to combine them. You can import the already combined vsl from /abcd/raw/summary/vsl.csv and tsl files if you just want to look at the analysis part.
#importing raw files
tsl <- list()
vsl <- list()
vsl_par_id <- NULL
tsl_par_id <- NULL
path <- "/Users/zhenghanqi/Dropbox (MIT)/UDel/projects/collaboration/abcd/raw/"
files <- list.files(path=path, pattern="*tsl.csv")
vsl_files <- list.files(path=path, pattern="*vsl.csv")
for(file in files)
{
assign(
gsub(" ","",file),
read.csv(paste(path,file,sep="")))
}
for(file in files){tsl <- append(tsl,list(eval(parse(text=file))))}
for(vslfile in vsl_files)
{
assign(
gsub(" ","",vslfile),
read.csv(paste(path,vslfile,sep="")))
}
for(text in vsl_files){vsl <- append(vsl,list(eval(parse(text=text))))}
vsl <- do.call(rbind.data.frame, vsl)
tsl <- do.call(rbind.data.frame, tsl)
#add an ID column for each row
for (i in seq(from=1,to=length(vsl$responses),by=length_vsl)){vsl_par_id<-append(vsl_par_id,rep(substr(vsl$responses[i],8,16),length_vsl))}
#Loading library
library(ggplot2)
library(knitr)
library(readr)
library(reshape)
library(reshape2)
library(lmerTest)
library(scales)
library(ggbeeswarm)
library(Hmisc)
#Initialize variables
total_participant <- 40 #40 vsl participants and 40 tsl participants
total_vsl_trial <- 24 #number of trials in the familiarization block
total_tsl_trial <- 48
length_vsl <- 533 #number of rows in a vsl excel file
length_tsl <- 832 #number of rows in a tsl excel file
total_test_trial <- 32
#Note: The code below is to work on the raw files to combine them. You can import the already combined vsl from /abcd/raw/summary/vsl.csv and tsl files if you just want to look at the analysis part.
#importing raw files
tsl <- list()
vsl <- list()
vsl_par_id <- NULL
tsl_par_id <- NULL
path <- "/Users/zhenghanqi/Dropbox (MIT)/UDel/projects/collaboration/abcd/raw/"
files <- list.files(path=path, pattern="*tsl.csv")
vsl_files <- list.files(path=path, pattern="*vsl.csv")
for(file in files)
{
assign(
gsub(" ","",file),
read.csv(paste(path,file,sep="")))
}
for(file in files){tsl <- append(tsl,list(eval(parse(text=file))))}
for(vslfile in vsl_files)
{
assign(
gsub(" ","",vslfile),
read.csv(paste(path,vslfile,sep="")))
}
for(text in vsl_files){vsl <- append(vsl,list(eval(parse(text=text))))}
vsl <- do.call(rbind.data.frame, vsl)
tsl <- do.call(rbind.data.frame, tsl)
#add an ID column for each row
for (i in seq(from=1,to=length(vsl$responses),by=length_vsl)){vsl_par_id<-append(vsl_par_id,rep(substr(vsl$responses[i],8,16),length_vsl))}
#import packages
Packages <- c("dplyr", "stats", "nFactors", "psych", "ggplot2", "lme4",
"gridExtra", "dplyr","caret","tidyverse", "ggplot2","plyr")
lapply(Packages, library, character.only = TRUE)
#import packages
Packages <- c("dplyr", "stats", "psych", "ggplot2", "lme4",
"gridExtra", "dplyr","caret","tidyverse", "ggplot2","plyr")
lapply(Packages, library, character.only = TRUE)
#set subject directory
#setwd("~/Dropbox (MIT)/learning_analysis")
setwd("~/Dropbox (MIT)/GitHub/procedural-learning")
#import pocedural.csv file
d <- read.csv('procedural_data062220.csv',stringsAsFactors = FALSE,skipNul = TRUE,
blank.lines.skip = TRUE)
groups<-read.csv(file = "~/Dropbox (MIT)/ABCD_analysis/ABCDStudy_2019-09-19.csv")[ ,c('ABCD.ID', 'Subgroup')]
d<-merge(d,groups)
names(d)[names(d)=="abcd_id"] <- "PartID"
SL=read.csv("SL_102818.csv")
SL<-merge
#Rename variables and organize
names(d)[names(d)=="ABCD.ID"] <- "PartID"
d2<-merge(d,SL)
#exclude ineligible participants
d<-d%>%filter(d$PartID!='ABCD_1718')
d2<-merge(d,SL)
#exclude ineligible participants
d<-d%>%filter(d$PartID!='ABCD_1718')
d<-d%>%filter(d$PartID!='ABCD_1728')
d2<-merge(d,SL)
d2<-dplyr::merge(d,SL)
#import packages
Packages <- c("dplyr", "stats", "psych", "ggplot2", "lme4",
"gridExtra", "dplyr","caret","tidyverse", "ggplot2","plyr")
lapply(Packages, library, character.only = TRUE)
####Organizational ####s
#set subject directory
#setwd("~/Dropbox (MIT)/learning_analysis")
setwd("~/Dropbox (MIT)/GitHub/procedural-learning")
#import pocedural.csv file
d <- read.csv('procedural_data062220.csv',stringsAsFactors = FALSE,skipNul = TRUE,
blank.lines.skip = TRUE)
groups<-read.csv(file = "~/Dropbox (MIT)/ABCD_analysis/ABCDStudy_2019-09-19.csv")[ ,c('ABCD.ID', 'Subgroup')]
d<-merge(d,groups)
names(d)[names(d)=="abcd_id"] <- "PartID"
SL=read.csv("SL_102818.csv")
SL<-merge
#Rename variables and organize
names(d)[names(d)=="ABCD.ID"] <- "PartID"
d2<-merge(d,SL)
SL=read.csv("SL_102818.csv")
names(d)[names(d)=="ABCD.ID"] <- "PartID"
d2<-merge(d,SL)
names(d)[names(d)=="ABCD.ID"] <- "PartID"
d2<-merge(d,SL)
d2<-merge(d,SL,'PartID')
d$PartID
str(d$PartID)
str(SL$PartID)
d2<-merge(d,SL,'PartID')
d$PartID
SL$PartID
#exclude ineligible participants
d<-d%>%filter(d$PartID!='ABCD_1718')
d<-d%>%filter(d$PartID!='ABCD_1728'
#exclude ineligible participants
d<-d%>%filter(d$PartID!='ABCD_1718')
d<-d%>%filter(d$PartID!='ABCD_1728')
#exclude ineligible participants
d<-d%>%filter(d$PartID!='ABCD_1718')
d<-d%>%filter(d$PartID!='ABCD_1728')
d$PartID
